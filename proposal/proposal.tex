\documentclass[ms]{byuprop}

% Options for this class include the following (* indicates default): 
%   10pt -- 10 point font size 
%   11pt -- 11 point font size 
%   12pt (*) -- 12 point font size 
%
%   ms -- produce a thesis proposal (off) 
%   areaexam -- produce a research area overview (off) 
%   phd -- produce a dissertation proposal (off) 
%
%   layout -- show layout lines on the pages, helps with overfull boxes (off) 
%   grid -- show a half-inch grid on every page, helps with printing (off)

% This command fixes my particular printer, which starts 0.03 inches too low, 
% shifting the whole page down by that amount. This shifts the document 
% content up so that it comes out right when printed. 
%
% Discovering this sort of behavior is best done by specifying the ``grid'' 
% option in the class parameters above.  It prints a 1/2 inch grid on every 
% page. You can then use a ruler to determine exactly what the printer is 
% doing. 
% Uncomment to shift content up (accounting for printer problems)
%\setlength{\voffset}{-.03in}

% Here we set things up for invisible hyperlinks in the document. This makes 
% the electronic version clickable without changing the way that the document 
% prints. It's useful, but optional. Note that if you use pdflatex, you 
% should change "ps2pdf" to "pdftex". 
\usepackage[
	pdftex,
	bookmarks=true,
	breaklinks=true,
	raiselinks=true,
	pdfborder={0 0 0},
	colorlinks=false,
	]{hyperref}

% Rewrite the itemize, description, and enumerate environments to have more 
% reasonable spacing: 
\newcommand{\ItemSep}{\itemsep 0pt}
\let\oldenum=\enumerate
\renewcommand{\enumerate}{\oldenum \ItemSep}
\let\olditem=\itemize
\renewcommand{\itemize}{\olditem \ItemSep}
\let\olddesc=\description
\renewcommand{\description}{\olddesc \ItemSep}

% Get a little less fussy about word spacing on a line.  Sometimes produces 
% ugly results, so keep your eyes peeled. 
\sloppy

% Important settings for the byuprop class. %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Because I use these things in more than one place, I created new commands for 
% them. I did not use \providecommand because I absolutely want LaTeX to error 
% out if these already exist. 

\newcommand{\Title}{The Monadic Semantics of Continuation Marks}
\newcommand{\Author}{Kimball R. Germane} 
\newcommand{\SubmissionMonth}{April}
\newcommand{\SubmissionYear}{2012}

% Take these from the commands defined above
\title{\Title}
\author{\Author}
\monthsubmitted{\SubmissionMonth} 
\yearsubmitted{\SubmissionYear}

% Committee members 
\committeechair{Jay McCarthy} 
\committeemembera{Sean Warnick} 
\committeememberb{}
\committeememberc{} 
\committeememberd{}

% Department graduate coordinator 
\graduatecoordinator{Dan Ventura}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Set up the internal PDF information so that it becomes part of the document 
% metadata. The pdfinfo command will display this. Be sure to set the document 
% type and add your own keywords. 
\hypersetup{%
	pdftitle=\Title,%
	pdfauthor=\Author,%
	pdfsubject={Document Type, BYU CS Department: %
				Submitted \SubmissionMonth~\SubmissionYear, Created \today},%
	pdfkeywords={},%
}

% These packages allow the bibliography to be sorted alphabetically and allow references
% to more than one paper to be sorted and compressed (i.e. instead of [5,2,4,6] you get
% [2,4-6]) 

%\usepackage[numbers,sort&compress]{natbib}
%\usepackage{hypernat}

% Additional packages required for your specific thesis go here. I've left some I use as
% examples. 
%\usepackage{graphicx}
%\usepackage{pdfsync}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{float}

\floatstyle{boxed} 
\restylefloat{figure}

\newcounter{definition}
\newcounter{example}

\begin{document}

% Produce the preamble
\maketitle


%\abstract{}

\section{Introduction}

% remember that the audience in this case actually does not know what these things are 
% so have a clear, useful exposition.

Thesis: Continuation marks are amenable to a monadic semantics.

% talk more about how they are useful here, elaboration will be below

Continuation marks \cite{clements2006portable} are a language feature that provides a
mechanism to annotate the dynamic context of a program. This feature allows the
association of arbitrary values with arbitrary keys for the lifetime of an execution
context and the inquiry of currently defined values of pending contexts for a given set of
keys. This is advantageous for programs that require dynamic information about a program
execution such as debuggers, profilers, and steppers because it allows them to be defined
at the same level as the language instead of some level below.

%For instance, <give a simple, useful, illustrative example here>.
% later we can talk about continuation marks and continuations, simulating dynamic scope, 
% recursion and tail recursion detection. 

% can I use the terms programming language feature and computational model interchangeably?

Monadic semantics originate from Moggi \cite{moggi1989computational} wherein they were
termed categorical semantics in reference to their category theoretic construction; a
monad is simply a monoid in the category of endofunctors \cite{mac1998categories}. Monadic semantics describe the
meaning of computational models such as partial computability, side-effectfulness, and
non-determinism. The appeal of using monads to specify semantics is significant: it allows
one to work with a pure computational logic, such as the lambda calculus, with a
particular model of computation in isolation, insulating the interactions between
different models. There are at least two direct benefits to this: First, it helps one
define and reason about a particular computational model absent from the noise of other
models and practical considerations. Second, no language feature is an island and when it
becomes necessary to investigate the interactions between models, the monadic construction
facilitates composition in a simple way.

% talk about how they are recognized as a good way to do things.
% they allow reasoning about a feature or model in isolation but, surprisingly, also are 
% composable

Thus, the statement that continuation marks are amenable to a monadic semantics means
simply that we can characterize them with a monad, simultaneously allowing us to express
the essence of continuation marks and reason about its interaction with other
computational models.

% ... what does it actually mean? if we can show it satisfies the mono requirement, is it 
% a computational model?
% we can describe what they are at the core and also how they interact with other 
% computational models

\section{Related Work}

\subsection{Monadic Semantics}

A denotational semantics of a language provides a precise definition of the meaning of
expressions in that language. Additionally, denotational semantics can be used to capture
properties of programs making it a great asset for language analysis. However useful, the
denotational approach exhibits contagion: the addition of a language construct often
contaminates the entire definition \cite{liang2009modular}. In this sense, is not a
modular approach and, for this reason, denotational semantics are often eschewed in favor
of a more tractable approach.

Behavioral semantics mitigate this problem somewhat with a different approach. Rather than
expressing an effect or property of the program, behavioral semantics express the
execution of the program on an abstract machine.

% why are behavioral semantics not modular enough?
% must all additions be made keeping mind of the current whole?

Monadic semantics provide a modular approach to precisely specifying language meaning
using either a denotational or behavioral approach. This type of semantics is so termed
because of the appeal to the \emph{monad}, a concept stemming from category theory. Moggi
\cite{moggi1989computational} applies monads as a categorical semantics of computational
models such as non-termination and non-determinism. It may be helpful to illustrate this
and, to do so, we require the following definitions:

\emph{Note: In the coming sections, we will reference certain laws which monads preserve.
Moggi \cite{moggi1989computational} and Wadler \cite{wadler1995monads} describe axioms of 
monadic behavior which are typically expressed in terms of fewer, more loaded operations. 
We will encounter two such characterizations in the following definitions.}
% there are like eight simple laws that collapse into three. find that paper that says this!

\newtheorem{monad}[definition]{Definition}

\begin{monad}
A \emph{monad} over a category $\mathcal{C}$ is a triple $(T,\eta,\mu)$ where
$T:\mathcal{C}\rightarrow\mathcal{C}$, $\eta:\mathrm{Id}_{\mathcal{C}}\rightarrow T$, and
$\mu:T^{2}\rightarrow T$ are \emph{natural transformations} and the following equations
hold:

\begin{itemize}
\item $\mu_{TA};\mu_{A}=T(\mu_{A});\mu_{A}$
\item $\eta_{TA};\mu{A}=\mathrm{id}_{TA}=T(\eta_{A});\mu_{A}$
\end{itemize}
\end{monad}

The above laws apply to the characterization of monads involving the primitives
\emph{unit} and \emph{join}. Wadler \cite{wadler1995monads} goes into more detail of this.
However, our discussion will refer to an alternate characterization, given below.

\newtheorem{kleisli}[definition]{Definition}

\begin{kleisli}
A \emph{Kleisli triple} over $\mathcal{C}$ is a triple $(T,\eta,\_^{*})$, where
$T:\mathrm{Obj}(\mathcal{C})\rightarrow \mathrm{Obj}(\mathcal{C})$, $\eta_{A}:A\rightarrow TA$,
$f^{*}:TA\rightarrow TB$ for $f:A\rightarrow TB$ and the following equations hold:

\begin{itemize}
\item $\eta_{A}^{*}=\mathrm{id}_{TA}$

This law represents the primitive \emph{return} which lifts naked values in $A$ into the monadic domain $TA$.

\item $\eta_{A};f^{*}=f$

This law represents the primitive \emph{bind} which maps monads across domains according to a given function $f$. \emph{bind} exploits the structure of $TA$ to apply $f$ to values in $A$ and combines the results in a structure-specific way to obtain a value in $TB$.

\item $f^{*};g^{*}=(f;g^{*})^{*}$

This law represents a sequencing property which must hold; namely, a monadic operation performed as part of a given $f$ must be able to be performed in turn.
\end{itemize}
\end{kleisli}

\subsubsection{Monad Examples}

Some examples of monads might be illustrative. More, and in more depth, can be found in 
Moggi \cite{moggi1991notions}.

\newtheorem{partiality}[example]{Example}

\begin{partiality}
Partiality

\begin{itemize}
\item $TA=A_{\bot}=A\cup \{\bot\}$
\item $\eta_{A}$ is the inclusion of $A$ into $A_{\bot}$
\item if $f:A\rightarrow TB$, then $f^{*}(\bot)=\bot$ and $f^{*}(a)=f(a)$ for $a\in A$
\end{itemize}
\end{partiality}

\newtheorem{nondeterminism}[example]{Example}

\begin{nondeterminism}
Nondeterminism

\begin{itemize}
\item $T(\cdot)$ is the covariant powerset function, i.e., $T(A)=\mathcal{P}(A)$ and 
$T(f)(X)$ is the image of $X$ along $f$.
\item $\eta_{A}$ is the singleton map $a\mapsto \{a\}$
\item $\mu_{A}$ is the big union map $X\mapsto\bigcup X$, i.e., if $f:A\rightarrow TB$ and $c\in TA$, then $f^{*}(c)=\cup_{x\in c}f(x)$
\end{itemize}
\end{nondeterminism}

\subsection{Continuation Marks}

There are certain tools that are indispensable to some programmers that concern the
behavior of their programs: debuggers, profilers, steppers, etc. Without these tools,
these programmers cannot justify the adoption of a language, however compelling it might
otherwise be. Traditionally, these tools are developed at the same level as the 
language, privy to incidental implementation detail, precisely because that detail 
enables these tools to function. This is problematic for at least two reasons. First, 
it couples the implementation of the tool with the implementation of the language, which
increases the cost to port to other platforms. If users become dependent upon these tools,
it can stall the advancement of the language and the adoption of new language features.
Second and more critical, it makes these tools unsound. For instance, debuggers typically
examine programs which have been compiled without optimizations. In general, this means 
that the debugged program has different behavior than the deployed program. This is 
obviously undesirable.

It is desirable to implement such tools at the same level as the language, removing
dependency upon the implementation an instead relying on definitional and behavioral
invariants. Continuation marks are a language-level feature that provide the information
necessary for these tools to function. Furthermore, languages which require stack
inspection to enforce security policies (\emph{Java}, \emph{C\#}) or support aspect
oriented programming (\emph{aspectj}) can be defined in terms of a simpler language with
continuation marks.

The feature of continuation marks itself is accessible via two surface level syntactic
forms: \emph{with-continuation-mark} and \emph{current-continuation-marks}.

\emph{with-continuation-mark} has three parameters: a key identifying the nature of the
continuation mark, an expression which value will be associated with this key, and an
expression within the dynamic extent of which a continuation mark will exist with this
key. In a Scheme-like syntax, it appears as so:

% will use slatex for the dissertation; too much of a hassle now
\texttt{(with-continuation-mark} \emph{key-expr} \emph{value-expr} \emph{body-expr}\texttt{)}

\emph{current-continuation-marks} has one parameter, a set of keys, and returns a list of
all the associated values set within the dynamic context of the invocation. Scheme-like,
it looks like this:


\texttt{(current-continuation-marks} \emph{key-set}\texttt{)}

Importantly, the result of this invocation provides no evidence of any portion of the
dynamic context lacking continuation marks with the specified keys. This preserves the
ability to perform optimizations without exposing details which would render the
optimizations unsound. This also requires special consideration of a language that
supports tail call optimization which is not an optimization in the above sense since the
behavior of which is present in the semantic definition of the language. In fact, 
\emph{body-expr} is in tail position; a language with tail call optimization will reflect 
this.

The canonical example to illustrate the behavior of continuation marks in the presence and
absence of tail recursion is the factorial function.

Figure \ref{fac-rec} illustrates the definitional recursive variant of the factorial
function. In this actualization, a cascade of multiplication operations builds as the
recursive calls are made. Each multiplication is computation that must be performed after
the recursive call of which the machine must keep track.

\begin{figure}
\begin{verbatim}
(define (fact n)
  (if (= n 0)
      1
      (* n (fact (- n 1)))))
\end{verbatim}
\caption{The definitionally recursive factorial function}
\label{fac-rec}
\end{figure}

Figure \ref{fac-tail-rec} illustrates the tail recursive manifestation of the factorial
function. In contrast to the function in figure \ref{fac-rec}, this formulation performs
the multiplication before the recursive call. Because the function has no pending
computations after the evaluation of the recursive call, the execution context need not
grow. Such a call is said to be in tail position.

\begin{figure}
\begin{verbatim}
(define (fact-tr n acc)
  (if (= n 0)
      acc
      (fact-tr (- n 1) (* n acc))))
\end{verbatim}
\caption{A tail-recursive variant of the factorial function}
\label{fac-tail-rec}
\end{figure}

Figures \ref{fac-rec-cm} and \ref{fac-tail-rec-cm} represent these two variants of the
factorial function augmented with continuation marks.

% what this means for continuation marks in the face of such behavior. First, it may be
% useful to determine exactly to what the term \emph{continuation} refers. According to ...,
% a continuation is simply ``the rest of the computation''. Consider the following versions
% [wc] of the previous functions enhanced with continuation marks.

\begin{figure}
\begin{verbatim}
(define (fact n)
  (if (= n 0)
      (begin
        (display (current-continuation-marks 'fact))
        1)
      (with-continuation-mark 'fact n (* n (fact (- n 1)))))
\end{verbatim}
\caption{The definitionally recursive factorial function augmented with continuation marks}
\label{fac-rec-cm}
\end{figure}

\begin{figure}
\begin{verbatim}
(define (fact-tr n acc)
  (if (= n 0)
      (begin
        (display (current-continuation-marks 'fact))
        acc)
      (with-continuation-mark 'fact n (fact-tr (- n 1) (* n acc))))
\end{verbatim}
\caption{The tail-recursive factorial function augmented with continuation marks}
\label{fac-tail-rec-cm}
\end{figure}

The result of \texttt{(fact 3)} would be

\begin{verbatim}
(1 2 3)
6
\end{verbatim}

whereas the result of \texttt{(fact-tr 3 1)} would be

\begin{verbatim}
(1)
6
\end{verbatim}

This difference is due to the growing continuation in the definitionally recursive
\texttt{fact}. Each call to \texttt{fact} has a pending computation--namely, the
multiplication--after the recursive call and so each necessitates the creation an
additional evaluation context. The effect of these additional contexts is that each
annotation is applied to a ``blank'' context and so all the annotations are preserved. In
the tail-recursive variant, there is no pending computation and therefore no additional
evaluation context. In this instance, the previous mark is overwritten with the new.

% since each represents future computation to be performed.]  [and so we should expect that our previous annotation be overwritten in some sense--replaced].


%explain continuation marks at a high level \cite{clements2006portable}
%explain monadic semantics at a high level

\section{Project Description}

We will demonstrate that continuation marks have a monadic semantics by producing a monad
that models a computation with continuation marks. We present two equivalent definitions 
for the semantics of continuation marks. The first is simply in terms of a language. While 
we will not involve this language in any proofs, it better conveys the essence of continuation 
marks absent any machine model, so we include it for clarity. The second is in terms of an 
abstract machine for which we provide the small step semantics. It is our reference 
implementation against which we will verify the behavior of our monad.

\subsection{Language Definition}

Figure \ref{domain-definition} presents the definition of expressions and values in our 
language. The left column denotes that expressions in our language are applications, variables, 
values, \emph{wcm} forms, or \emph{ccm} forms. The right column denotes that values in the 
language are $\lambda$-abstractions.

\begin{figure}
\begin{align*}
e = &(e\,e) & v = \lambda x. e\\
    &x\\
    &v\\
    &(\mathrm{wcm}\,e\,e)\\
    &(\mathrm{ccm})
\end{align*}
\caption{Domain definition}
\label{domain-definition}
\end{figure}

Figure \ref{language-definition} presents both the syntactic forms of the language and the 
definition of a metafunction, $\chi$, in terms of those forms. The left column of figure 
\ref{language-definition} establishes static relationships between language forms. In these 
definitions, $E$ and $F$ signify ``holes'' in the computation--that is, where the current 
evaluation will be inserted. The distinction between $E$ and $F$ is made to enforce a 
definitional constraint: the evaluation of the mark occurs before the evaluation of the 
body. (This constraint is crucial in the face of mutation.) The corresponding rules in the 
right column describe the evaluation of the $\chi$ metafunction upon which the evaluation 
of the \emph{ccm} form depends.

\begin{figure}
\begin{align*}
E = &(\mathrm{wcm}\,v\,F) & \chi((\mathrm{wcm}\,v\,F)) &= v : (\chi(F))\\
    &F\\
F = &[]                   & \chi([])                   &= \mathrm{empty}\\
    &(E\,e)               & \chi((E\,e))               &= \chi(E)\\
    &(v\,E)               & \chi((v\,E))               &= \chi(E)\\
    &(\mathrm{wcm}\,E\,e) & \chi((\mathrm{wcm}\,E\,e)) &= \chi(E)
\end{align*}
\caption{Grammar and the $\chi$ metafunction}
\label{language-definition}
\end{figure}

The definitions in figure \ref{language-semantics} establish the proper interpretation of various expressions. The first follows the typical definition of application. The second defines the tail behavior of the \emph{wcm} form. The third expresses that the \emph{wcm} form takes on the value of its body. Finally, the fourth defines the value of the \emph{ccm} form in terms of the $\chi$ metafunction.

\begin{figure}
\begin{align*}
E[(\lambda x.e)\,v]                         &= E[e[x\leftarrow v]]\\
E[(\mathrm{wcm}\,v\,(\mathrm{wcm}\,v'\,e))] &= E[(\mathrm{wcm}\,v'\,e)]\\
E[(\mathrm{wcm}\,v\,v')]                    &= E[v']\\
E[(\mathrm{ccm})]                           &= E[\chi(E)]
\end{align*}
\caption{Evaluation rules}
\label{language-semantics}
\end{figure}

\subsection{Machine Model Definition}

Figure \ref{machine-definition} presents the definition of the machine model of continuation 
marks and the corresponding definition of the $\chi$ metafunction. The machine $S$ is defined 
as a triple of the control $C$ representing the term under evaluation, the environment $E$ 
defined as a function from identifiers to values, and the continuation $K$ representing a 
sequence of pending contexts.

The term $C$ under evaluation can be in various forms: a simple variable, a $\lambda$-abstraction, 
an application, a \emph{wcm} expression, or a \emph{ccm} expression.

Machine values $V$ are closures, a pair of a $\lambda$-abstraction and an environment $E$.

The continuation $K$ is defined recursively. It is a sequence beginning with $\bullet\,e,E$ 
denoting a function application context in which the function value is under evaluation, 
$v\,\bullet$ denoting the same in which the argument value is under evaluation, $\mathrm{wcm}\,
\bullet\,e$ denoting a \emph{wcm} expression context in which the continuation mark is under 
evaluation, $\mathrm{wcm}\,v$ denoting the same in which the body is under evaluation, or 
$\mathrm{halt}$ representing an empty sequence--the empty continuation. (Here, $\bullet$ 
represents a ``hole'' in the computation.) 

Adjacent to the definition of the continuation $K$ is the definition of the $\chi$ metafunction 
in terms of the various forms of $K$.

\begin{figure}
\begin{align*}
S= & \langle C,E,K\rangle\\
C= & x\\
   & \lambda x.e\\
   & e\,e\\
   & \mathrm{wcm}\,e\,e\\
   & \mathrm{ccm}\\
E= & \mathrm{Id}\rightarrow\mathrm{Value}\\
V= & \langle\lambda x.e,E\rangle\\
K= & \bullet\,e,E;k               & \chi(\bullet\,e,E;k)=\chi(k)\\
   & v\,\bullet;k                 & \chi(v\,\bullet;k)=\chi(k)\\
   & \mathrm{wcm}\,\bullet\,e,E;k & \chi(\mathrm{wcm}\,\bullet\,e,E;k)=\chi(k)\\
   & \mathrm{wcm}\,v; k           & \chi(\mathrm{wcm}\,v; k)=v:\chi(k)\\
   & \mathrm{halt}                & \chi(\mathrm{halt})=\mathrm{empty}
\end{align*}
\caption{Machine definition with corresponding $\chi$ metafunction definition}
\label{machine-definition}
\end{figure}

Figure \ref{machine-semantics} presents the small step semantics of the machine model 
introduced in figure \ref{machine-definition}. Program evaluation is defined as

\[
\frac{\langle e,\emptyset,\mathrm{halt}\rangle\rightarrow^{*}\langle V,E,\mathrm{halt}\rangle}{eval(e)=V}
\]

where an expression combined with an empty environment and empty continuation constitute 
a program.

\begin{figure}
\begin{align*}
\langle x,E,k\rangle                                       &\rightarrow\langle E[x],E,k\rangle\\
\langle\lambda x.e,E,k\rangle                              &\rightarrow\langle \langle\lambda x.e,E\rangle,E,k\rangle\\
\langle e\,e',E,k\rangle                                   &\rightarrow\langle e,E,(\bullet\,e',E);k\rangle\\
\langle v,E,(\bullet\,e',E');k\rangle                      &\rightarrow\langle e',E',v\,\bullet;k\rangle\\
\langle v,E,\langle\lambda x.e,E'\rangle\,\bullet;k\rangle &\rightarrow\langle e,E'[x\mapsto v],k\rangle\\
\langle \mathrm{wcm}\,e\,e',E,k\rangle                     &\rightarrow\langle e,E,(\mathrm{wcm}\,\bullet e',E);k\rangle\\
\langle v,E,\mathrm{wcm}\,\bullet e',E';k\rangle           &\rightarrow\langle e',E',\mathrm{wcm}\,v;f(k)\rangle\\
\langle v,E,\mathrm{wcm}\,v';k\rangle                      &\rightarrow\langle v,E,k\rangle\\
\langle \mathrm{ccm},E,k\rangle                            &\rightarrow\langle \chi(k),E,k\rangle
\end{align*}

where 

\[
f(x)=
\left\{
\begin{array}{lr}
k & \mathrm{if}\,x=\mathrm{wcm}\,v;k\\
x & \mathrm{otherwise}
\end{array}
\right.
\]

\caption{Machine semantics for continuation marks}
\label{machine-semantics}
\end{figure}

%produce and provide haskell implementation of a continuation mark monad produce and
%provide haskell implementation of continuation marks according to formal semantics show
%algebraically (i.e., solely through symbolic manipulation) that provided is a monad show
%in the same way that what it models and what the semantics describe are equivalent profit

As is typical, we will use the programming language Haskell \cite{jones2003haskell} for
our implementation and equational analysis. Haskell is a purely functional programming
language and, as such, all side effects are explicit. This is a great boon when reasoning
about a function because distant, implicit effects are impossible in this environment. In
other words, a function will \emph{always} produce the same output given the same input.
Because of this, functions can be analyzed singly and then composed in a way which removes
none of the guarantees attained in isolation. (We note that this is one of the useful
characteristics of monads also.)

%This property facilitates a bottom-up approach to program testing and validation. all its 

Another consequence of this is that input and output are not expressible as simple
functions. Each of these exhibit non-local effects and it is therefore impossible to
realize them as such. In order to perform a computation with I/O, we must model a
computation with I/O which is done by a properly crafted monad. The \texttt{IO} monad is
Haskell is the correct and endorsed method to perform I/O in a computation. Haskell has
many other regularly-used monads modelling computations with state, non-determinism,
continuations and exceptions, etc. Haskell is then a natural choice to implement and
verify a monad which models computations with continuation marks.

\section{Validation}

% it is intended that this section answer "how can we show this is a good solution?" this
% is the hardest of sciences and so it is implied that any proposed solution we provide will
% be accompanied by formal proof and we have stated we will supply it. that makes this
% section out-of-place.

In order to show that our construct is indeed a monad for continuation marks, we must show
that we our construct is a genuine monad and that it actually models continuation marks.

The mathematical basis of a monad lends three laws that fully specify the behavior of a 
monad. We will provide a proof that our construct satisfies these laws and can thus be 
correctly termed a monad. This proof is by nature algebraic.

Continuation marks themselves already have a formal operational semantics specified. To 
verify that our monad models continuation marks, we will prove that our monad is 
algebraically equivalent to the accepted operational semantic definition.

Thus, by demonstrating that our construct follows the monadic laws and has the semantics
of continuation, we will demonstrate that continuation marks have a monadic semantics.

%It may be the case that we have something that \emph{appears} to be a continuation mark
%monad but is not actually. In order to verify that our construct is a genuine continuation
%mark monad, we must do the following things:

%First, we must show that it actually models continuation marks. Continuation marks
%already have a denotational semantics defined. We can use equational
%reasoning/algebraically compare the semantics of the monad against the denotation
%semantics. What's more, if we express them in a suitable language, we can run our
%research.

%Second, we must show that it actually is a monad. We can verify the construct satisfies
%the three monad laws algebraically.

%explain what is necessary to show that what we have are continuation marks and what we
%have is a monad

%monadic semantics accomplish [their purpose] by providing an abstraction barrier which
%hides irrelevant...

%something about real programs?

\section{Thesis Schedule}

Less than five years.

%Abstract – 1 to 2 paragraphs summarizing the proposal. Introduction – 1 to 4 pages
%answering questions 1 and 2 above Related Work – 1 to 2 pages answering question 3 above.
%Thesis statement – 1 to 2 sentences stating what is to be demonstrated in your thesis.
%Project Description – 2 to 5 pages answering question 4 above. Validation – 1/2 to 2 pages
%answering question 5 above. Thesis Schedule – ¼ to ½ page specifying dates for completion
%of major milestones. Annotated Bibliography – 2 to 5 pages containing references for all
%work cited.

%%%%%%%%%%%%%%%%%%%%%%%%%

% Change these to reflect the bibliography style and bibtex database file you want to use
\bibliographystyle{annotate}
\bibliography{proposal}

\end{document}
