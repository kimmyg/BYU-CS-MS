\documentclass[ms,electronic,twosidetoc,letterpaper,chaptercenter,parttop]{byumsphd}
% Author: Chris Monson
%
% This document is in the public domain
%
% Options for this class include the following (* indicates default):
%
%   phd (*) -- produce a dissertation
%   ms -- produce a thesis
%
%   electronic -- default official university option, overrides the following:
%                 - equalmargins
%
%   hardcopy -- overrides the following:
%                 - no equalmargins
%                 - twoside
%
%   letterpaper -- ignored, but helpful for the Makefile that I use
%
%   10pt -- 10 point font size
%   11pt -- 11 point font size
%   12pt (*) -- 12 point font size
%
%   lof -- produce a list of figures in the preamble (off)
%   lot -- produce a list of tables in the preamble (off)
%   lol -- produce a list of listings in the preamble (off)
%
%   layout -- show layout lines on the pages, helps with overfull boxes (off)
%   grid -- show a half-inch grid on every page, helps with printing (off)
%   separator -- print an extra instruction page between preamble and body (off)
%
%   twoside (*) -- two-sided output (margins alternate for odd and even pages,
%     blank pages inserted to ensure that chapters begin on the right side of a
%     bound copy, etc.)
%   oneside -- one-sided output (margins are the same on all pages)
%   equalmargins -- make all margins equal - ugly for binding, but compliant
%
%   twosidetoc - start two-sided margins at the TOC instead of the body.  This
%     is sometimes (oddly) required, but be aware that it will make the page
%     numbering seem screwy, e.g., the first four full sheets of paper will
%     have number i-iv (not shown, though), and the next sheets will each have
%     two numbers, one for each side.  I suspect that most people don't look at
%     the roman numerals anyway, but it is a weird requirement.
%
%   openright (*) -- force new chapters to start on an odd page
%   openany -- don't use this, it's ugly
%
%   prettyheadings -- make the section/chapter headings look nice
%   compliantheadings (*) -- make them look ugly, but compliant with standards
%
%   chaptercenter -- center the chapter headings horizontally
%   chapterleft (*) -- place chapter headings on the left
%
%   partmiddle -- Part headers are centered vertically, no other text on page
%   parttop (*) -- Part headers at top of page, other text expected
%
%   duplexprinter -- Ensures that the two-sided portion starts on the right
%     side when printing.  This is not for use in submission, since the best
%     thing to do there is to print everything out one-sided, then take it down
%     to the copy store to have them do the rest.  It does help to save trees
%     when you are printing out copies just to look at them and fiddle with
%     things.
%
%
% EXAMPLES:
%
% The rest is up to you.  To fiddle with margins, use the \settextwidth and
% \setbindingoffset macros, described below.  I suggest that you
% \settextwidth{6.0in} for better-looking output (otherwise you'll get 3/4-inch
% margins after binding, which is sort of weird).  This will depend on the
% opinions of the various dean/coordinator folks, though, so be sure to ask
% them before embarking on a major formatting task.

% The following command fixes my particular printer, which starts 0.03 inches
% too low, shifting the whole page down by that amount.  This shifts the
% document content up so that it comes out right when printed.
%
% Discovering this sort of behavior is best done by specifying the ``grid''
% option in the class parameters above.  It prints a 1/2 inch grid on every
% page.  You can then use a ruler to determine exactly what the printer is
% doing.
%
% Uncomment to shift content up (accounting for printer problems)
%\setlength{\voffset}{-.03in}

% Here we set things up for invisible hyperlinks in the document.  This makes
% the electronic version clickable without changing the way that the document
% prints.  It's useful, but optional.
%
% NOTE: "driverfallback=ps2pdf" chooses ps2pdf in the case of LaTeX and pdftex
% in the case of pdflatex. If you use my LaTeX makefile (at
% http://latex-makefile.googlecode.com/) then pdftex is the default There are
% many other benefits to using the makefile, too.  This option is not always
% available, so use with care.
\usepackage[
    bookmarks=true,
    bookmarksnumbered=true,
    breaklinks=false,
    raiselinks=true,
    pdfborder={0 0 0},
    colorlinks=false,
    plainpages=false,
    ]{hyperref}

% To fiddle with the margin settings use the below.  DO NOT change stuff
% directly (like setting \textwidth) - it will break subtle things and you'll
% be tearing your hair out.
%
% For example, if you want 1.5in equal margins, or 2in and 1in margins when
% printing, add the following below:
%
%\setbindingoffset{1.0in}
%\settextwidth{5.5in}
%
% When equalmargins is specified in the class options, the margins will be
% equal at 1.5in each: (8.5 - 5.5) / 2.  When equalmargins is not specified,
% the inner margin will be 2.0 and the outer margin will be 1.0: inner = (8.5 -
% 5.5 - 1.0) / 2 + 1.0 (the 1.0 is the binding offset).
%
% The idea is this: you determine how much space the text is going to take up,
% whether for an electronic document (equalmargins) or not.  You don't want the
% layout shifting around between printed and electronic documents.
%
% So, you specify the text width.  Then, if there is a binding offset (when
% binding your thesis, the binding takes up space - usually 0.5 inches), that
% reduces the visual space on the final printed copy.  So, the *effective*
% margins are calculated by reducing the page size by the binding offset, then
% computing the remaining space and dividing by two.  Adding back in the
% binding offset gives the inner margin.  The outer margin is just what's left.
%
% All of this is done using the geometry package, which should be manipulated
% directly at your peril.  It's best just to use the above macros to manipulate
% your margins.
%
% That said, using the geometry macro to set top and bottom margins, or
% anything else vertical, is perfectly safe and encouraged, e.g.,
%
%\geometry{top=2.0in,bottom=2.0in}
%
% Just don't fiddle with horizontal margins this way.  You have been warned.

% This makes hyperlinks point to the tops of figures, not their captions
\usepackage[all]{hypcap}

% These packages allow the bibliography to be sorted alphabetically and allow references to more than one paper to be sorted and compressed (i.e. instead of [5,2,4,6] you get [2,4-6])
\usepackage[numbers,sort&compress]{natbib}
\usepackage{hypernat}

% Because I use these things in more than one place, I created new commands for
% them.  I did not use \providecommand because I absolutely want LaTeX to error
% out if these already exist.
\newcommand{\Title}{A CPS-like Transformation of Continuation Marks}
\newcommand{\Author}{Kimball R. Germane}
\newcommand{\GraduationMonth}{September}
\newcommand{\GraduationYear}{2012}

% Set up the internal PDF information so that it becomes part of the document
% metadata.  The pdfinfo command will display this.
\hypersetup{%
    pdftitle=\Title,%
    pdfauthor=\Author,%
    pdfsubject={MS Dissertation, BYU CS Department: %
                Degree Granted \GraduationMonth~\GraduationYear, Document Created \today},%
    pdfkeywords={BYU, thesis, dissertation, LaTeX},%
}

% Rewrite the itemize, description, and enumerate environments to have more
% reasonable spacing:
\newcommand{\ItemSep}{\itemsep 0pt}
\let\oldenum=\enumerate
\renewcommand{\enumerate}{\oldenum \ItemSep}
\let\olditem=\itemize
\renewcommand{\itemize}{\olditem \ItemSep}
\let\olddesc=\description
\renewcommand{\description}{\olddesc \ItemSep}

% Important settings for the byumsphd class.
\title{\Title}
\author{\Author}

\committeechair{Jay McCarthy}
\committeemembera{Sean Warnick}
\committeememberb{a}
\committeememberc{b}
\committeememberd{c}

\monthgraduated{\GraduationMonth}
\yeargraduated{\GraduationYear}
\yearcopyrighted{\GraduationYear}

\documentabstract{%
This document is an example of how to use the byumsphd {\LaTeX} class file.  The class creates Ph.D. and Master's documents equally well, producing all appropriate preamble content and adhering precisely to the minimum formatting requirements.  It is meant to replace the old ECEn style file that has been circulating for many years.

Note that there is a blank line between paragraphs, here.
}

\documentkeywords{%
    Thesis template, poorly-crafted example, conflicting margin instructions
}

\acknowledgments{%
    Thanks go to the ECEn style file authors for providing both a reasonable initial style and the motivation to abandon it.
}

\department{Computer~Science}
\graduatecoordinator{Dan~Ventura}
\collegedean{Thomas~W.~Sederberg}
\collegedeantitle{Associate~Dean}

% Customize the name of the Table of Contents section.
\renewcommand\contentsname{Table of Contents}

% Remove all widows an orphans.  This is not normally recommended, but in a
% paper dissertation there is no reasonable way around it; you can't exactly
% rewrite already-published content to fix the problem.
\clubpenalty 10000
\widowpenalty 10000

% Allow pages to have extra blank space at the bottom in order to accommodate
% removal of widows and orphans.
\raggedbottom

% Produce nicely formatted paragraphs. There is nothing additional to do.  In
% case you get some problems, surround your text with
% \begin{sloppy} ... \end{sloppy}. If that does not work, try
% \microtypesetup{protrusion=false} ... \microtypesetup{protrusion=true}
\usepackage{microtype}

\usepackage{amsmath}

\begin{document}

% Produce the preamble
\microtypesetup{protrusion=false}
\maketitle
\microtypesetup{protrusion=true}

\section{Introduction}

Thesis: A CPS-like global transformation can compile the $\lambda$-calculus with
continuation marks into the plain $\lambda$-calculus in a semantics-preserving way.

Continuation marks \cite{clements2006portable} are a language feature that provides a
mechanism to annotate the dynamic context of a program. This feature allows the
association of arbitrary values with arbitrary keys for the lifetime of an execution
context and the inquiry of currently defined values of pending contexts for a given set of
keys. This is advantageous for programs that require dynamic information about a program
execution such as debuggers, profilers, and steppers because it allows them to be defined
at the same level as the language instead of some level below.

The continuation-passing style (CPS) transformation is actually a family of 
transformations designed to make certain analyses simpler. The simplest variation of the 
CPS transformation augments each function with an additional formal parameter, the 
\emph{continuation}, which is a functional representation of currently pending 
computation. Functions in CPS never return; instead, they call the continuation argument 
with their result. The CPS transformation then simplifies programs by representing all 
control and data transfer uniformly and explicitly. In general, the ``spirit'' of the 
CPS transformation is to represent all transfers of control uniformly \cite{sabry1994formal}.

It is our interest to understand the essence of continuation marks--their behavior in the 
absense of other language features and implementation details. For this, we take the core 
of computation, the $\lambda$-calculus, and add facilities to manipulate continuation 
marks. These two together comprise a language which we term $\lambda_{cm}$. By expressing 
$\lambda_{cm}$ in terms of the plain $\lambda$-calculus, we uncover the meaning of 
continuation marks in a pure computational language. We arrive at this expression by 
performing a transformation in the spirit of CPS from $\lambda_{cm}$ to the $\lambda$-calculus 
verified to preserve the meaning of the source language.

\section{Continuation marks}

There are certain tools that are indispensable to some programmers that concern the
behavior of their programs: debuggers, profilers, steppers, etc. Without these tools,
these programmers cannot justify the adoption of a language, however compelling it might
otherwise be. Traditionally, these tools are developed at the same level as the 
language, privy to incidental implementation detail, precisely because that detail 
enables these tools to function. This is problematic for at least two reasons. First, 
it couples the implementation of the tool with the implementation of the language, which
increases the cost to port to other platforms. If users become dependent upon these tools,
it can stall the advancement of the language and the adoption of new language features.
Second and more critical, it makes these tools unsound. For instance, debuggers typically
examine programs which have been compiled without optimizations. In general, this means 
that the debugged program has different behavior than the deployed program. This is 
obviously undesirable.

It is desirable to implement such tools at the same level as the language, removing
dependency upon the implementation an instead relying on definitional and behavioral
invariants. Continuation marks are a language-level feature that provide the information
necessary for these tools to function. Furthermore, languages which require stack
inspection to enforce security policies (\emph{Java}, \emph{C\#}) or support aspect
oriented programming (\emph{aspectj}) can be defined in terms of a simpler language with
continuation marks.

Continuation marks originated in PLT Scheme (now Racket \cite{plt-tr1}) as a stack 
inspection mechanism. In fact, the \emph{Java} and \emph{C\#} languages rely on a similar 
stack inspection to enforce security policies of which continuation marks can be seen as 
a generalization. Surprisingly, continuation marks can be encoded in any language with 
exception facilities \cite{pettyjohn2005continuations} which fact has led to their 
experimental addition to Javascript \cite{clements2008implementing}.

The feature of continuation marks itself is accessible via two surface level syntactic
forms: \emph{with-continuation-mark} and \emph{current-continuation-marks}.

\emph{with-continuation-mark} has three parameters: a key expression \emph{key-expr}, a 
value expression \emph{value-expr} and a body expression \emph{body-expr}. The evaluation 
of \emph{value-expr} will be associated with a key, the evaluation of \emph{key-expr}, 
before the evaluation of \emph{body-expr}. During the lifetime of the evaluation of 
\emph{body-expr}, a continuation mark will exist associated with this key. In a Scheme-like 
syntax, this call appears like so:

% will use slatex for the dissertation; too much of a hassle now
\texttt{(with-continuation-mark} \emph{key-expr} \emph{value-expr} \emph{body-expr}\texttt{)}

\emph{current-continuation-marks} has one parameter, a set of keys \emph{key-set}, and returns a list of
all the associated values attached to the dynamic context of the invocation. If a particular 
context has been annotated by more than one key in the set, this will be reflected in the 
returned list\footnote{The returned list is typically a list of non-empty lists where each 
sub-list represents the marks on a context.}. Additionally, the order in which values were 
attached with a particular key is preserved. Scheme-like, \emph{current-continuation-marks}
looks like this:

\texttt{(current-continuation-marks} \emph{key-set}\texttt{)}

Importantly, the result of \emph{current-continuation-marks} provides no evidence of any portion of the
dynamic context lacking continuation marks with the specified keys. This preserves the
ability to perform optimizations without exposing details which would render the
optimizations unsound. This also requires special consideration of a language that
supports tail call optimization (which is not an optimization in the above sense since its
behavior is defined in the semantics of the language). By definition, \emph{body-expr} is 
in tail position; a language with tail call optimization will reflect this.

The canonical example to illustrate the behavior of continuation marks in the presence and
absence of proper tail recursion is the factorial function.

Figure \ref{fac-rec} illustrates the definitional recursive variant of the factorial
function. In this actualization, a cascade of multiplication operations builds as the
recursive calls are made. Each multiplication is computation that must be performed after
the recursive call of which the machine must keep track.

\begin{figure}
\begin{verbatim}
(define (fact n)
  (if (= n 0)
      1
      (* n (fact (- n 1)))))
\end{verbatim}
\caption{The definitionally recursive factorial function}
\label{fac-rec}
\end{figure}

Figure \ref{fac-tail-rec} illustrates the tail recursive manifestation of the factorial
function. In contrast to the function in figure \ref{fac-rec}, this formulation performs
the multiplication before the recursive call. Because the function has no pending
computations after the evaluation of the recursive call, the execution context need not
grow. Such a call is said to be in tail position.

\begin{figure}
\begin{verbatim}
(define (fact-tr n acc)
  (if (= n 0)
      acc
      (fact-tr (- n 1) (* n acc))))
\end{verbatim}
\caption{A tail-recursive variant of the factorial function}
\label{fac-tail-rec}
\end{figure}

Figures \ref{fac-rec-cm} and \ref{fac-tail-rec-cm} represent these two variants of the
factorial function augmented with continuation marks. Using these definitions, the 
result of \texttt{(fact 3)} would be

\begin{verbatim}
(((fact 1)) ((fact 2)) ((fact 3)))
6
\end{verbatim}

whereas the result of \texttt{(fact-tr 3 1)} would be

\begin{verbatim}
(((fact 1)))
6
\end{verbatim}.

\begin{figure}
\begin{verbatim}
(define (fact n)
  (if (= n 0)
      (begin
        (display (current-continuation-marks '(fact)))
        1)
      (with-continuation-mark 'fact n (* n (fact (- n 1)))))
\end{verbatim}
\caption{The definitionally recursive factorial function augmented with continuation marks}
\label{fac-rec-cm}
\end{figure}

\begin{figure}
\begin{verbatim}
(define (fact-tr n acc)
  (if (= n 0)
      (begin
        (display (current-continuation-marks '(fact)))
        acc)
      (with-continuation-mark 'fact n (fact-tr (- n 1) (* n acc))))
\end{verbatim}
\caption{The tail-recursive factorial function augmented with continuation marks}
\label{fac-tail-rec-cm}
\end{figure}

This difference is due to the growing continuation in the definitionally recursive
\texttt{fact}. Each call to \texttt{fact} has a pending computation--namely, the
multiplication--after the recursive call and so each necessitates the creation an
additional evaluation context. The effect of these additional contexts is that each
annotation is applied to a new, ``blank'' context, so all the annotations are preserved. 
In the tail-recursive variant, there is no pending computation and therefore no additional
evaluation context. In this instance, the previous mark is overwritten with the new.

\section{CPS transformations}

The CPS transformation is a family of language transformations derived from Plotkin \cite{plotkin1975call} and designed to simplify  programs by representing all data and control flow uniformly and explicitly, in turn simplifying compiler construction and analyses such as optimization and verification \cite{sabry1994formal}. The standard variation adds a formal parameter to every function definition and an argument to every call site.

As an example, consider once again the two variants of the factorial function, sans continuation 
marks, given earlier. In CPS, the properly recursive variant can be expressed as
\begin{verbatim}
(define (fact n k) 
  (if (= n 0)
      (k 1)
      (fact (- n 1) (lambda (acc) (k (* n acc))))))
\end{verbatim}
and the tail-recursive variant as
\begin{verbatim}
(define (fact-tr n acc k)
  (if (= n 0)
      (k acc)
      (fact-tr (- n 1) (* n acc) k)))
\end{verbatim}. (For clarity, we have treated ``primitive'' functions--equality 
comparison, subtraction, and multiplication--in a direct manner. In contrast, a 
full CPS transformation would affect \emph{every} function.)

Notice that, in the first variation, each recursive call receives a newly-constructed 
$k$ encapsulating additional work to be performed at the completion of the recursive 
computation. In the second, $k$ is passed unmodified, so while computation occurs 
within each context, no \emph{additional} computation pends. From this example, we 
see that the CPS representation is ideal for understanding tail-call behavior as it 
is explicit that the continuation is preserved by the tail call.

The purpose of CPS does not lie solely in pedagogy, however. The reification of and 
consequent ability to directly manipulate the continuation is a powerful ability, 
analogous in power to the ability to \emph{capture} a continuation which some 
languages provide. In Scheme, this is accomplished with \emph{call/cc}, short for 
``call with current continuation''. This call takes one argument which itself is a 
function of one argument. \emph{call/cc} calls its argument, passing in a functional 
representation of the current continuation--the continuation present when \emph{call/cc} 
was invoked. This continuation function takes one argument which is treated as the result 
of \emph{call/cc} and runs this continuation to completion.

As a simple example,
\begin{verbatim}
(+ 1 (call/cc
       (lambda (k)
         (k 1))))
\end{verbatim}
returns $2$. In effect, invoking $k$ with the value 1 is the same as replacing 
the entire \emph{call/cc} invocation with the value 1.

Much of the power of \emph{call/cc} lies in the manifestation of the continuation 
as a function, giving it first-class status. It can be passed as an argument in 
function calls, invoked, and, amazingly, reinvoked at leisure. It is this 
reinvokeability that makes \emph{call/cc} the fundamental unit of control from 
which all other control structures can be built, including generators, coroutines, 
and threads.

%\emph{call/cc} is erroneously seen as incredibly heavyweight and overkill for 
%control (cite something). This conception probably comes from the conceptualization 
%of the continuation as the call stack and continuation capture as stack copy while 
%continuation call is stack installation. It is also seen as a form of \emph{goto} 
%which is known to obfuscate control flow and impede analysis (cite something). 
%[Can't and shouldn't talk much about the second. Probably take it out.] Bearing in 
%mind that the CPS transformation aids compilers, it is useful to investigate the 
%characterization of \emph{call/cc} within the standard CPS transformation.

In direct style, the definition of \emph{call/cc} is conceptually 
\begin{verbatim}
(define call/cc
  (lambda (f)
    (f (get-function-representing-continuation))))
\end{verbatim}
where \emph{get-function-representing-continuation} is an opaque function which 
leverages sweeping knowledge of the language implementation. The CPS definition 
is notably easier:
\begin{verbatim}
(define call/cc
  (lambda (f k)
    (f k k)))
\end{verbatim}

Variations on the standard CPS transformation can make the expression of certain 
control structures more straightforward. For instance, the ``double-barrelled'' 
CPS transformation is a variation wherein each function signature receives not 
one but two additional formal parameters, each a continuation. One application 
of this particular variation is error handling with one continuation argument 
representing the remainder of a successful computation and the other representing 
the failure contingency. It is especially useful in modelling exceptions and 
other non-local transfers of control in situations where the computation might fail.
In general, the nature of the CPS transformation allows it to untangle 
complicated, intricate control structures.

Similar transformations exist which express other programming language features 
such as security annotations \cite{wallach2000safkasi} and control structures 
such as procedures, exceptions, labelled jumps, coroutines, and 
backtracking. On top of other offerings, this places it in a category of tools 
to describe and analyze programming language features. (This category is also 
occupied by Moggi's computational lambda calculus--monads 
\cite{moggi1989computational}.)


One of the reasons CPS is useful is that is allows evaluation order to be controlled. This is done by 
a definitional invariant: every term applied to a continuation returns a value. We will visit each 
case of the definition and verify this property. Before doing so, we emphasize that no reduction is 
performed by effect of the transformation.

\[
T[x]=\lambda k.(k x)
\]

Variables are values, so the property holds immediately here.

\[
T[\lambda x.E]=\lambda k.(k \lambda x.T[E])\]

Here we reason inductively by assuming that the property holds for E. Abstractions are values, so the 
property holds in this case also.

\[
T[E F]=\lambda k.(T[E] (\lambda e.(T[F] (\lambda f.((e f) k))))
\]

Once again, we assume that the property holds for E and F. Then e and f are values. In order to conclude 
that the property holds for the application, we must establish that the application of values yields a 
value. The key lies in a case analysis of the operator. It must be either a variable or an abstraction.

First, consider the application of a variable to a variable.

\[
x y
\]

This is fully reduced according to direct application.

\begin{align*}
T[x y] &= \lambda k.(T[x] (\lambda e.T[y] (\lambda f.((e f) k))))\\
       &= \lambda k.(\lambda k.(k x) (\lambda e.T[y] (\lambda f.((e f) k))))\\
       &= \lambda k.(\lambda k.(k x) (\lambda e.\lambda k.(k y) (\lambda f.((e f) k))))\\
\end{align*}

We can evaluate this expression by applying it to the identity function $\lambda z.z$.

\begin{align*}
&\rightarrow \lambda k.(\lambda k.(k x) (\lambda e.\lambda k.(k y) (\lambda f.((e f) k)))) \lambda z.z\\
&\rightarrow \lambda k.(k x) (\lambda e.\lambda k.(k y) (\lambda f.((e f) \lambda z.z)))\\
&\rightarrow \lambda e.\lambda k.(k y) (\lambda f.((e f) \lambda z.z)) x\\
&\rightarrow \lambda k.(k y) (\lambda f.((x f) \lambda z.z))\\
&\rightarrow \lambda f.((x f) \lambda z.z) y\\
&\rightarrow (x y) \lambda z.z\\
\end{align*}

Similar to a direct-style application, we remain stuck.

Now, consider the application of an abstraction to a variable.

\[
\lambda x.x y
\]

This reduces to y, of course, when directly applied.

\begin{align*}
T[\lambda x.x y] &= \lambda k.(T[\lambda x.x] (\lambda e.(T[y] (\lambda f.((e f) k))))\\
                 &= \lambda k.(\lambda k.(k \lambda x.T[x]) (\lambda e.(T[y] (\lambda f.((e f) k))))\\
                 &= \lambda k.(\lambda k.(k \lambda x.\lambda k.(k x)) (\lambda e.(T[y] (\lambda f.((e f) k))))\\
                 &= \lambda k.(\lambda k.(k \lambda x.\lambda k.(k x)) (\lambda e.\lambda k.(k y) (\lambda f.((e f) k))))\\
\end{align*}

Apply the identity function $\lambda z.z$ to this term.

\begin{align*}
&\rightarrow \lambda k.(\lambda k.(k \lambda x.\lambda k.(k x)) (\lambda e.\lambda k.(k y) (\lambda f.((e f) k)))) \lambda z.z\\
&\rightarrow \lambda k.(k \lambda x.\lambda k.(k x)) (\lambda e.\lambda k.(k y) (\lambda f.((e f) \lambda z.z)))\\
&\rightarrow (\lambda e.\lambda k.(k y) (\lambda f.((e f) \lambda z.z))) \lambda x.\lambda k.(k x)\\
&\rightarrow \lambda k.(k y) (\lambda f.((\lambda x.\lambda k.(k x) f) \lambda z.z))\\
&\rightarrow \lambda f.((\lambda x.\lambda k.(k x) f) \lambda z.z) y\\
&\rightarrow (\lambda x.\lambda k.(k x) y) \lambda z.z\\
&\rightarrow \lambda k.(k y) \lambda z.z\\
&\rightarrow \lambda z.z y\\
&\rightarrow y\\
\end{align*}

We observe that, at the time of application, the remnant of the transformation of $\lambda x.x$ took the form 
$\lambda x.\lambda k.(k x)$. This is a term which, when applied, will yield a value. We can generalize our reasoning 
to establish this property for all applications by considering

$T[\lambda x.E F]$

and noting that E also satisfies this property.

[could perhaps do something more detailed and formal here]

Suppose we want to embed direct-style terms in CPS terms. We are interested in what cases we can induce 
reduction.

As an example which will become useful later, suppose we want to deal with a Church encoding of lists 
directly.

Recall that we can represent \emph{nil} as [the Church encoding of] \emph{false} and \emph{cons a b} as 
$\lambda p.((p a) b)$.

Like [the transformation] T, C has a similar property which we quickly verify:

\begin{align*}
C[x]           &= \lambda k.\lambda m.(k x)\\
C[\lambda x.E] &= \lambda k.\lambda m.(k \lambda x.C[E])\\
C[E F]         &= \lambda k.\lambda m.((C[E] (\lambda e.((C[F] (\lambda f.(((e f) k) m))) g[m]))) g[m])\\
C[wcm E F]     &= \lambda k.\lambda m.((C[E] (\lambda e.((C[F] k) h[e,m]))) g[m])\\
C[ccm]         &= \lambda k.\lambda m.(k i[m])\\
\end{align*}

where g[m]=cons false (snd m)
and h[e,m]=cons true (if fst m then rest (snd m) else snd m)
and i[m]=snd m

We use the definitions $g$, $h$, and $i$ to emphasize that these facilities enjoy privileged status 
in the transformation definition and are invisible to the program.

-uses
-lambda calculus
-reference CPS due to Fischer/Plotkin
-properties

Redex [cite redex] is a domain-specific language for exploring language semantics. It lives very 
close to the semantics notation we have used in this discussion. To illustrate how easily langagues 
can be defined in Redex, we will examine a Redex program which defines a toy language. In contrast to 
a Redex tutorial, we will not concern ourselves with the syntax and structure of roads not taken and 
will instead briefly explain each component of the program.

\begin{verbatim}
(define-language toy
  (x variable-not-otherwise-mentioned)
  (v number undefined) 
  (e (+ e e) (with (x e) e) x v)
  (E hole (+ E e) (+ v E) (with (x E) e)))
\end{verbatim}

This expression defines the abstract syntactic structure of a language named \emph{toy}. There are 
four categories of structures: $x$, $v$, $e$, and $E$. The category $x$ is defined to contain any 
token not otherwise mentioned in the definition. The category $v$ is defined to contain numbers 
and the token \emph{undefined}. The category $e$ is defined to contain the expression forms of 
the language, of which there are four: addition expressions, \emph{with} expressions, lone 
variables, and lone values. The last category, $E$, does not define abstract syntax but instead 
reduction contexts. A reduction context, according to this definition, is either a hole (a special 
token in Redex) which is the destination of a result [say that better] or ... various forms which 
dictate evaluation order.

\begin{verbatim}
(define toy-rr
  (reduction-relation
   toy
   (--> (in-hole E (+ number_1 number_2))
        (in-hole E ,(+ (term number_1) (term number_2)))
        "+")
   (--> (in-hole E (with (x_1 v_1) e_1))
        (in-hole E (substitute x_1 v_1 e_1))
        "with")
   (--> (in-hole E x_1)
        (in-hole E undefined)
        "free variable")
   (--> (in-hole E (+ undefined e_1))
        (in-hole E undefined)
        "undefined in first position")
   (--> (in-hole E (+ number_1 undefined))
        (in-hole E undefined)
        "undefined in second position")))
\end{verbatim}

This term defines the reduction relation of the \emph{toy} language. The five defined reductions, 
signalled by \texttt{-->}, match specified patterns and manipulate them according to the defined 
rules. These define: the addition of two numbers; the substitution of a \emph{with} expression; 
a lone variable; the addition of an undefined value on the left; and the addition of an undefined 
value on the right.

\begin{verbatim}
(define-metafunction toy
  substitute : x v e -> e
  [(substitute x_1 v_1 (+ e_1 e_2))
   (+ (substitute x_1 v_1 e_1) (substitute x_1 v_1 e_2))]
  [(substitute x_1 v_1 (with (x_1 e_1) e_2))
   (with (x_1 (substitute x_1 v_1 e_1)) e_2)]
  [(substitute x_1 v_1 (with (x_2 e_1) e_2))
   (with (x_2 (substitute x_1 v_1 e_1)) (substitute x_1 v_1 e_2))]
  [(substitute x_1 v_1 x_1)
   v_1]
  [(substitute x_1 v_1 x_2)
   x_2]
  [(substitute x_1 v_1 v_2)
   v_2])

(define value? (redex-match toy v))
(define variable? (redex-match toy x))

(define (reduces-to-one-value-or-variable? e)
  (let ((results (apply-reduction-relation* toy-rr e)))
    (and (= (length results) 1)
         (or (value? (first results))
             (variable? (first results))))))

(define (reduces-to-one-value? e)
  (begin
    (display e)
    (newline)
    (let ((results (apply-reduction-relation* toy-rr e)))
      (and (= (length results) 1)
           (value? (first results))))))

(redex-check toy
             e
             (reduces-to-one-value? (term e)))
\end{verbatim}

Plotkin's CPS transformation abstracts each term in the $\lambda$-calculus: lone variables wait on a continuation, abstractions receive a degree of indirection, and even applications, the sole reduction facility of the $\lambda$-calculus, become abstractions. In essence, terms become suspended in wait of a continuation argument. By priming a term so-transformed with a continuation function, even as simple as the identity, we instigate a cascade of computation. In the case of lone variables and applications, we see that this transformation has no effect on the result. However, the values of the $\lambda$-calculus--abstractions--are contaminated by the transform. For example

\[
T[\lambda x.x]=\lambda k.(k \lambda x.\lambda k.(k x))
\].

It is for this reason that we must take special care with our transform which is based on Plotkin's.

\section{C}
\subsection{properties of C}
\subsection{preservation theorem}
-informally analyze time/space complexity (via reductions)
-introduce ``direct-style'' transform (using static/dynamic continuation?)
\section{Future work}
-use this idea in compiler?
\section{Conclusion}
\bibliographystyle{plainnat}
\bibliography{dissertation}

\end{document}

% vim: lbr
