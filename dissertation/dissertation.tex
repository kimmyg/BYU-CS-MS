\documentclass[ms,electronic,twosidetoc,letterpaper,chaptercenter,parttop]{byumsphd}
% Author: Chris Monson
%
% This document is in the public domain
%
% Options for this class include the following (* indicates default):
%
%   phd (*) -- produce a dissertation
%   ms -- produce a thesis
%
%   electronic -- default official university option, overrides the following:
%                 - equalmargins
%
%   hardcopy -- overrides the following:
%                 - no equalmargins
%                 - twoside
%
%   letterpaper -- ignored, but helpful for the Makefile that I use
%
%   10pt -- 10 point font size
%   11pt -- 11 point font size
%   12pt (*) -- 12 point font size
%
%   lof -- produce a list of figures in the preamble (off)
%   lot -- produce a list of tables in the preamble (off)
%   lol -- produce a list of listings in the preamble (off)
%
%   layout -- show layout lines on the pages, helps with overfull boxes (off)
%   grid -- show a half-inch grid on every page, helps with printing (off)
%   separator -- print an extra instruction page between preamble and body (off)
%
%   twoside (*) -- two-sided output (margins alternate for odd and even pages,
%     blank pages inserted to ensure that chapters begin on the right side of a
%     bound copy, etc.)
%   oneside -- one-sided output (margins are the same on all pages)
%   equalmargins -- make all margins equal - ugly for binding, but compliant
%
%   twosidetoc - start two-sided margins at the TOC instead of the body.  This
%     is sometimes (oddly) required, but be aware that it will make the page
%     numbering seem screwy, e.g., the first four full sheets of paper will
%     have number i-iv (not shown, though), and the next sheets will each have
%     two numbers, one for each side.  I suspect that most people don't look at
%     the roman numerals anyway, but it is a weird requirement.
%
%   openright (*) -- force new chapters to start on an odd page
%   openany -- don't use this, it's ugly
%
%   prettyheadings -- make the section/chapter headings look nice
%   compliantheadings (*) -- make them look ugly, but compliant with standards
%
%   chaptercenter -- center the chapter headings horizontally
%   chapterleft (*) -- place chapter headings on the left
%
%   partmiddle -- Part headers are centered vertically, no other text on page
%   parttop (*) -- Part headers at top of page, other text expected
%
%   duplexprinter -- Ensures that the two-sided portion starts on the right
%     side when printing.  This is not for use in submission, since the best
%     thing to do there is to print everything out one-sided, then take it down
%     to the copy store to have them do the rest.  It does help to save trees
%     when you are printing out copies just to look at them and fiddle with
%     things.
%
%
% EXAMPLES:
%
% The rest is up to you.  To fiddle with margins, use the \settextwidth and
% \setbindingoffset macros, described below.  I suggest that you
% \settextwidth{6.0in} for better-looking output (otherwise you'll get 3/4-inch
% margins after binding, which is sort of weird).  This will depend on the
% opinions of the various dean/coordinator folks, though, so be sure to ask
% them before embarking on a major formatting task.

% The following command fixes my particular printer, which starts 0.03 inches
% too low, shifting the whole page down by that amount.  This shifts the
% document content up so that it comes out right when printed.
%
% Discovering this sort of behavior is best done by specifying the ``grid''
% option in the class parameters above.  It prints a 1/2 inch grid on every
% page.  You can then use a ruler to determine exactly what the printer is
% doing.
%
% Uncomment to shift content up (accounting for printer problems)
%\setlength{\voffset}{-.03in}

% Here we set things up for invisible hyperlinks in the document.  This makes
% the electronic version clickable without changing the way that the document
% prints.  It's useful, but optional.
%
% NOTE: "driverfallback=ps2pdf" chooses ps2pdf in the case of LaTeX and pdftex
% in the case of pdflatex. If you use my LaTeX makefile (at
% http://latex-makefile.googlecode.com/) then pdftex is the default There are
% many other benefits to using the makefile, too.  This option is not always
% available, so use with care.
\usepackage[
    bookmarks=true,
    bookmarksnumbered=true,
    breaklinks=false,
    raiselinks=true,
    pdfborder={0 0 0},
    colorlinks=false,
    plainpages=false,
    ]{hyperref}

% To fiddle with the margin settings use the below.  DO NOT change stuff
% directly (like setting \textwidth) - it will break subtle things and you'll
% be tearing your hair out.
%
% For example, if you want 1.5in equal margins, or 2in and 1in margins when
% printing, add the following below:
%
%\setbindingoffset{1.0in}
%\settextwidth{5.5in}
%
% When equalmargins is specified in the class options, the margins will be
% equal at 1.5in each: (8.5 - 5.5) / 2.  When equalmargins is not specified,
% the inner margin will be 2.0 and the outer margin will be 1.0: inner = (8.5 -
% 5.5 - 1.0) / 2 + 1.0 (the 1.0 is the binding offset).
%
% The idea is this: you determine how much space the text is going to take up,
% whether for an electronic document (equalmargins) or not.  You don't want the
% layout shifting around between printed and electronic documents.
%
% So, you specify the text width.  Then, if there is a binding offset (when
% binding your thesis, the binding takes up space - usually 0.5 inches), that
% reduces the visual space on the final printed copy.  So, the *effective*
% margins are calculated by reducing the page size by the binding offset, then
% computing the remaining space and dividing by two.  Adding back in the
% binding offset gives the inner margin.  The outer margin is just what's left.
%
% All of this is done using the geometry package, which should be manipulated
% directly at your peril.  It's best just to use the above macros to manipulate
% your margins.
%
% That said, using the geometry macro to set top and bottom margins, or
% anything else vertical, is perfectly safe and encouraged, e.g.,
%
%\geometry{top=2.0in,bottom=2.0in}
%
% Just don't fiddle with horizontal margins this way.  You have been warned.

% This makes hyperlinks point to the tops of figures, not their captions
\usepackage[all]{hypcap}

% These packages allow the bibliography to be sorted alphabetically and allow references to more than one paper to be sorted and compressed (i.e. instead of [5,2,4,6] you get [2,4-6])
\usepackage[numbers,sort&compress]{natbib}
\usepackage{hypernat}

% Because I use these things in more than one place, I created new commands for
% them.  I did not use \providecommand because I absolutely want LaTeX to error
% out if these already exist.
\newcommand{\Title}{A CPS-like Transformation of Continuation Marks}
\newcommand{\Author}{Kimball R. Germane}
\newcommand{\GraduationMonth}{September}
\newcommand{\GraduationYear}{2012}

% Set up the internal PDF information so that it becomes part of the document
% metadata.  The pdfinfo command will display this.
\hypersetup{%
    pdftitle=\Title,%
    pdfauthor=\Author,%
    pdfsubject={MS Dissertation, BYU CS Department: %
                Degree Granted \GraduationMonth~\GraduationYear, Document Created \today},%
    pdfkeywords={BYU, thesis, dissertation, LaTeX},%
}

% Rewrite the itemize, description, and enumerate environments to have more
% reasonable spacing:
\newcommand{\ItemSep}{\itemsep 0pt}
\let\oldenum=\enumerate
\renewcommand{\enumerate}{\oldenum \ItemSep}
\let\olditem=\itemize
\renewcommand{\itemize}{\olditem \ItemSep}
\let\olddesc=\description
\renewcommand{\description}{\olddesc \ItemSep}

% Important settings for the byumsphd class.
\title{\Title}
\author{\Author}

\committeechair{Jay McCarthy}
\committeemembera{Sean Warnick}
\committeememberb{Dennis Ng}
%\committeememberc{b}
%\committeememberd{c}

\monthgraduated{\GraduationMonth}
\yeargraduated{\GraduationYear}
\yearcopyrighted{\GraduationYear}

\documentabstract{%
Continuation marks are a programming language feature which generalize stack inspection. Despite its usefulness, this feature has not been adopted by languages which rely on stack inspection, e.g., for dynamic security checks. One reason for this neglect may be that continuation marks do not yet enjoy a transformation to the plain $\lambda$-calculus which would allow higher-order languages to provide continuation marks at little cost.

We present a CPS-like transformation from the call-by-value $\lambda$-calculus augmented with continuation marks to the pure call-by-value $\lambda$-calculus. We discuss how this transformation simplifies the construction of compilers which treat continuation marks correctly. We document an iterative, feedback-based approach using Redex. We accompany the transformation with a meaning-preservation theorem.
}

\documentkeywords{%
    continuation marks, continuation-passing style, Redex
}

\acknowledgments{%
Thanks to R.L. Stine for showing me that a chapter doesn't have to be more than two pages.

My wife is the hottest thing ever.
}

\department{Computer~Science}
\graduatecoordinator{Dan~Ventura}
\collegedean{Thomas~W.~Sederberg}
\collegedeantitle{Associate~Dean}

% Customize the name of the Table of Contents section.
\renewcommand\contentsname{Table of Contents}

% Remove all widows an orphans.  This is not normally recommended, but in a
% paper dissertation there is no reasonable way around it; you can't exactly
% rewrite already-published content to fix the problem.
\clubpenalty 10000
\widowpenalty 10000

% Allow pages to have extra blank space at the bottom in order to accommodate
% removal of widows and orphans.
\raggedbottom

% Produce nicely formatted paragraphs. There is nothing additional to do.  In
% case you get some problems, surround your text with
% \begin{sloppy} ... \end{sloppy}. If that does not work, try
% \microtypesetup{protrusion=false} ... \microtypesetup{protrusion=true}
\usepackage{microtype}

\usepackage{float}
\floatstyle{boxed}
\restylefloat{figure}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{slatex}
\setkeyword{with-continuation-mark current-continuation-marks wcm ccm}
\setkeyword{fac fac-tr}
\setkeyword{display}
\setkeyword{get-function-representing-continuation call/cc}
\setspecialsymbol{lambda}{$\lambda$}

\newcommand{\lc}{$\lambda$-calculus}
\newcommand{\lv}{$\lambda_v$}
\newcommand{\la}{$\lambda_n$}
\newcommand{\cm}{$\lambda_{cm}$}

\newcommand{\true}{\mathbf{true}}
\newcommand{\false}{\mathbf{false}}
\newcommand{\nil}{\mathbf{nil}}
\newcommand{\pair}[2]{((\mathbf{pair}\,#1)\,#2)}
\newcommand{\eval}[1]{\overline{#1}}

\newcommand{\lvrr}{\rightarrow_{\lambda_v}}
\newcommand{\lvrrs}{\rightarrow_{\lambda_v}^{*}}
\newcommand{\larr}{\rightarrow_{\lambda_n}}
\newcommand{\larrs}{\rightarrow_{\lambda_n}^{*}}
\newcommand{\cmrr}{\rightarrow_{\lambda_{cm}}}
\newcommand{\cmrrs}{\rightarrow_{\lambda_{cm}}^{*}}
\newcommand{\C}[1]{\mathcal{C}[#1]}
\newcommand{\Ct}[2]{\mathcal{C}[#1,#2]}
\newcommand{\Cone}[1]{\mathcal{C}_1[#1]}
\newcommand{\Cp}[1]{\mathcal{C}'[#1]}
\newcommand{\Ch}[1]{\hat{\mathcal{C}}[#1]}
\newcommand{\Ccps}[1]{\mathcal{C}_{\mathrm{cps}}[#1]}
\newcommand{\Cpcps}[1]{\mathcal{C}'_{\mathrm{cps}}[#1]}
\newcommand{\Chcps}[1]{\hat{\mathcal{C}}_{\mathrm{cps}}[#1]}
\newcommand{\evalv}[1]{\mathrm{eval}_v(#1)}
\newcommand{\evalcm}[1]{\mathrm{eval}_{cm}(#1)}

\newcommand{\abs}[2]{(\lambda\,(#1)\,#2)}
\newcommand{\app}[2]{(#1\,#2)}
\newcommand{\wcm}[2]{(\mathrm{wcm}\,#1\,#2)}
\newcommand{\ccm}{(\mathrm{ccm})}

\newcommand{\hole}{\bullet}

\begin{document}

% Produce the preamble
\microtypesetup{protrusion=false}
\maketitle
\microtypesetup{protrusion=true}

\chapter{Introduction}

Thesis: A CPS-like global transformation can compile the \lc\ with continuation marks into
the plain \lc\ in a semantics-preserving way.

Numerous programming language instruments rely on stack inspection to function. Statistical profilers sample the stack regularly to record active functions, algebraic steppers observe the stack to represent the evaluation context of an expression, and debuggers naturally require consistent access to the stack. Each of these relies on implementation-specific information and must be maintained as the instrumented language undergoes optimizations and ventures across platforms. This makes these tools brittle and increases the porting cost of the language ecosystem. Each of these examples would benefit from a generalized stack-inspection mechanism available within the instrumented language itself. If written in such an enhanced language, each instrument would be more robust, more easily modified, and would port for free.

Continuation marks \cite{clements2006portable} are a programming language feature which generalizes stack inpection. Not only do they dramatically simplify correct instrumentation \cite{clements2001modeling}, they have been used to allow inspection-based dynamic security checks in the presence of tail-call optimization \cite{clements2004tail} and to express aspect-oriented programming in higher-order languagues \cite{tucker2003pointcuts}.

In spite of their usefulness, continuation marks have remained absent from programming languages at large. One reason for this is that retrofitting virtual machines to accommodate the level of stack inspection continuation marks must provide is expensive, especially when the virtual machines use the host stack for efficiency.

For example, the ubiquitous JavaScript is an ideal candidate for the addition of continuation marks. However, as the lingua franca of the web, it has numerous mature implementations which have been heavily optimized; to add continuation marks to JavaScript amounts to modifying each implementation upstream, to say nothing of amending the JavaScript standard. (Clements et al. successfully added continuation marks in Mozilla's Rhino compiler \cite{clements2008implementing}, but it remains a proof-of-concept.)

To avoid this roadblock, we instead take a macro-style approach; that is, we enhance the core language with facilities to manipulate continuation marks and desugar the enhanced language back to the core. To make our desugaring transformation apply to many languages, we define it over the \lc, the common core of most higher-order languages. With such a transformation, language semanticists do not need to reconcile the feature with other features in the language (provided they have already done so with $\lambda$) and their compiler writers do not need to worry about complicating their implementations (for the same reason).

The \lc\ is a Turing-complete formal logic based on variable binding and substitution.
Where the Turing machine model of computation is machine-centric, the \lc\ model is
language-centric. Thus, it conveniently serves as an intermediate representation for a
compiler or a base from which to define higher-level languages. The standard
reference to the \lc\ is Barendregt \cite{barendregt1984lambda}.

The continuation-passing style (CPS) transformation is actually a family of
language transformations designed to make certain analyses simpler. Every member of this family
shares a common trait: their performance augments each function with an additional formal
parameter, the \emph{continuation}, a functional representation of currently pending
computation. Functions in CPS never explicitly return; instead, they call the continuation
argument with their result. Because no function ever returns, function calls are the final
act of the caller. Thus, all calls are tail calls. The CPS transformation then simplifies
programs by representing all control and data transfer uniformly and explicitly. In
general, the ``spirit'' of the CPS transformation is to represent all transfers of control
uniformly \cite{sabry1994formal}.

We take the core of computation, the \lc, and add facilities to manipulate continuation
marks. These two together comprise a language which we term \cm. By expressing \cm\ in
terms of the plain \lc, we uncover the meaning of continuation marks in a pure
computational language absent other language features and implementation details. To do
this, we construct $\mathcal{C}$, a transformation from \cm\ programs to \lc\ programs in
the spirit of CPS. We use Redex \cite{findler2010redex} to test candidate transformations
for correctness. This allows us to increase our confidence in a functioning transformation
but cannot demonstrate correctness. We address this shortcoming by providing and proving a
meaning preservation theorem.

\chapter{Continuation marks}

There are certain tools that are indispensable to some programmers that concern the
behavior of their programs: debuggers, profilers, steppers, etc. Without these tools,
these programmers cannot justify the adoption of a language, however compelling it might
otherwise be. Traditionally, these tools are developed at the same level the language is,
privy to incidental implementation detail, precisely because that detail enables these
tools to function. This is problematic for at least two reasons. First, it couples the
implementation of the tool with the implementation of the language, which increases the
cost to port to other platforms. If users become dependent upon these tools, it can stall
the advancement of the language and the adoption of new language features. Second and more
critical, it makes these tools unsound. For instance, debuggers typically examine programs
which have been compiled without optimizations. In general, this means that the debugged
program has different behavior than the deployed program. This is obviously undesirable.

It is desirable to implement such tools at the same level as the language, removing
dependency upon the implementation and instead relying on definitional and behavioral
invariants. Continuation marks are a language-level feature that provide the information
necessary for these tools to function. Furthermore, languages which require stack
inspection to enforce security policies (\emph{Java}, \emph{C\#}) or support aspect
oriented programming (\emph{aspectj}) can be defined in terms of a simpler language with
continuation marks \cite{clements2004tail, tucker2003pointcuts}.

Continuation marks originated in PLT Scheme (now Racket \cite{plt-tr1}) as a stack 
inspection mechanism. In fact, the \emph{Java} and \emph{C\#} languages rely on a similar 
stack inspection to enforce security policies of which continuation marks can be seen as 
a generalization. Surprisingly, continuation marks can be encoded in any language with 
exception facilities \cite{pettyjohn2005continuations}.



The feature of continuation marks itself is accessible via two surface level syntactic
forms: \scheme{with-continuation-mark} and \scheme{current-continuation-marks}.

In Scheme-like syntax, a \scheme{with-continuation-mark} expression appears as
\scheme|(with-continuation-mark key-expr value-expr body-expr)|. The evaluation of this
expression proceeds by first evaluating \scheme{key-expr} to \scheme{key} and
\scheme{value-expr} to \scheme{value}. Thereafter, \scheme{body-expr} is evaluated within
the extent of which \scheme'value' is associated with \scheme 'key'.

For instance, in the expression \scheme|(with-continuation-mark 'fun 'cons (cons 0
empty))|, the value \scheme{'+} is associated with the key \scheme{'fun} during the
evaluation of \scheme|(+ 2 2)|.

In the same Scheme-like syntax, a \scheme{current-continuation-marks} expression appears
as \scheme|(current-continuation-marks key-list)|. This expression evaluates to a list of
all the present key-value associations referenced in \scheme{key-list}. The
\scheme{with-continuation-mark} form admits a notion of ordering--inner associations are
more recent than outer ones--and this in reflected in the list yielded by the
\scheme{current-continuation-marks}.

Importantly, the result of \scheme{current-continuation-marks} provides no evidence of any
portion of the dynamic context lacking continuation marks with the specified keys. This
preserves the ability to perform optimizations without exposing details which would render
the optimizations unsound. This also requires special consideration of a language that
supports tail call optimization (which is not an optimization in the above sense since its
behavior is defined in the semantics of the language).

The canonical example to illustrate the behavior of continuation marks in the presence and
absence of tail call optimization is the factorial function.

Figure \ref{fac-rec} illustrates the definitional recursive variant of the factorial
function. In this actualization, a cascade of multiplication operations builds as the
recursive calls are made. Each multiplication is pending computation of which the machine 
must keep track.

\begin{figure}
\begin{schemedisplay}
(define (fac n)
  (if (= n 0)
      1
      (* n (fac (- n 1)))))
\end{schemedisplay}
\caption{The definitionally recursive factorial function}
\label{fac-rec}
\end{figure}

Figure \ref{fac-tail-rec} illustrates the tail recursive manifestation of the factorial
function. In contrast to the function in figure \ref{fac-rec}, this formulation performs
the multiplication before the recursive call. Because the function has no pending
computations after the evaluation of the recursive call, the execution context need not
grow. Such a call is said to be in tail position.

\begin{figure}
\begin{schemedisplay}
(define (fac-tr n acc)
  (if (= n 0)
      acc
      (fac-tr (- n 1) (* n acc))))
\end{schemedisplay}
\caption{A tail-recursive variant of the factorial function}
\label{fac-tail-rec}
\end{figure}

Figures \ref{fac-rec-cm} and \ref{fac-tail-rec-cm} represent these two variants of the
factorial function augmented with continuation marks. Using these definitions, the 
result of \scheme|(fac 3)| would be

\begin{schemedisplay}
(((fac 1)) ((fac 2)) ((fac 3)))
6
\end{schemedisplay}

whereas the result of \scheme|(fac-tr 3 1)| would be

\begin{schemedisplay}
(((fac 1)))
6
\end{schemedisplay}

\begin{figure}
\begin{schemedisplay}
(define (fac n)
  (if (= n 0)
      (begin
        (display (current-continuation-marks '(fac)))
        1)
      (with-continuation-mark 'fac n (* n (fac (- n 1)))))
\end{schemedisplay}
\caption{The definitionally recursive factorial function augmented with continuation marks}
\label{fac-rec-cm}
\end{figure}

\begin{figure}
\begin{schemedisplay}
(define (fac-tr n acc)
  (if (= n 0)
      (begin
        (display (current-continuation-marks '(fac)))
        acc)
      (with-continuation-mark 'fac n (fac-tr (- n 1) (* n acc))))
\end{schemedisplay}
\caption{The tail-recursive factorial function augmented with continuation marks}
\label{fac-tail-rec-cm}
\end{figure}

This difference is due to the growing continuation in the definitionally recursive
\scheme{fac}. Each call to \scheme{fac} has a pending computation--namely, the
multiplication--after the recursive call and so each necessitates the creation of
additional evaluation context. The effect of this additional context is that each
annotation is applied to new, ``blank'' context, so all the previous annotations are
preserved. In the tail-recursive variant, there is no pending computation and therefore no
additional evaluation context. In this instance, the previous mark is overwritten with the
new.

\chapter{\lc}

The \lc\ is a Turing-complete system of logic extensively used as a formal system for
expressing computation. Terms in the \lc\ are defined inductively; they take the form of
variables $x$ drawn from an infinite set, abstractions $\abs{x}{M}$ where $M$ is itself a
\lc\ term, and applications $\app{M}{N}$ where $M$ and $N$ are \lc\ terms.

Variables in the \lc\ are either free or bound. A variable $x$ is free if it does not
reside in the scope of a \emph{binding instance} of $x$. Otherwise, $x$ is bound. Bound
variables play a special part in the role of the \lc\ as a computation substrate. Terms
with no free variables can be called closed terms, combinators, or programs. The fact that
variables are drawn from an infinite set means that, given an arbitrary \lc\ term, we can
always obtain a \emph{fresh variable}, a variable not present in the term at hand. This is
critical as we will see shortly.

In an abstraction of the form $\abs{x}{M}$, $x$ is a binding instance which binds all free
occurrences of $x$ in the body $M$. To a first approximation, abstractions are functions.
For instance, the identity function can be expressed as $\abs{x}{x}$ where $x$ is
\emph{any} variable. Thus, there are an infinite number of ways to express the identity
function: $\abs{x}{x}$, $\abs{y}{y}$, $\abs{z}{z}$, etc. It is important to note that,
while they are not syntactically equivalent, these terms denote the same function. This
fact gives rise to the notion of $\alpha$-equivalence which captures the idea that
consistent renaming of bound variables does not change the meaning of a term. There is
some subtlety in valid renaming as there is the possibility of \emph{variable capture}
which occurs when the new name of a binding instance is identical to that of some variable
already present in the body. For instance, in the term $\abs{x}{y}$, if each $x$ is
renamed to $y$, we obtain the term $\abs{y}{y}$, a fundamentally different term. For this
reason, we need to take special care when we rename variables, which we will need to do
regularly.

One of the ways abstractions approximate functions is that we can apply them to arguments.
This is signified simply by juxtaposition of function (or operator) and argument (or
operand). In the correct context, an application of the form $\app{M}{N}$ can be
\emph{reduced} in which the operator $M$ is applied to the operand $N$. For $M$ of the
form $\abs{x}{M'}$ for some $M'$, this entails the substitution of every free occurrence
of $x$ in $M'$ with $N$. The notation we adopt for this is $M'[x\leftarrow N]$. For
instance, the application $\app{\abs{x}{x}}{y}$ signifies $x[x\leftarrow y]$ and so
reduces to $y$. Here, we must protect against another strain of variable capture. As an
example, consider the reduction of $\app{\abs{x}{\abs{y}{x}}}{y}$. If we reduce naively,
we obtain $\abs{y}{y}$ which does not reflect the intended meaning of the reduction--the
argument $y$ has been captured by the abstraction, an act which destroys its meaning
within the environment. In order to avoid this, we must rename capturing abstractions in
$M$ to be outside the set of free variables of $N$. Within the greater term
$\app{\abs{x}{\abs{y}{x}}}{y}$, we rename $y$ to $z$ in $\abs{x}{\abs{y}{x}}$ obtaining
$\abs{x}{\abs{z}{x}}$. The subsequent reduction of $\app{\abs{x}{\abs{z}{x}}}{y}$ to
$\abs{z}{y}$ correctly reflects the intended meaning of the original term.

In the \lc, evaluation occurs during reduction, and reduction is merely application. There
is, however, yet more subtlety of which we must be aware: namely, in which contexts
applications are performed and terms evaluated. In the call-by-value \lc, denoted \lv,
evaluation of operands occurs before application. In contrast, in the call-by-name \lc,
denoted \la, application is performed as soon as the operator is resolved.

For instance, in $\app{\abs{x}{x}}{\app{\abs{y}{y}}{\abs{z}{z}}}$,
\begin{align*}
      &\app{\abs{x}{x}}{\app{\abs{y}{y}}{\abs{z}{z}}}\\
\lvrr &\app{\abs{x}{x}}{\abs{z}{z}}\\
\lvrr &\abs{z}{z}
\end{align*}
whereas
\begin{align*}
      &\app{\abs{x}{x}}{\app{\abs{y}{y}}{\abs{z}{z}}}\\
\lvrr &\app{\abs{y}{y}}{\abs{z}{z}}\\
\lvrr &\abs{z}{z}
\end{align*}
Although both terms reduce to the same term in this example, this distinction is not
merely pedantic: terms may reduce definitively in one reduction regime and fail to reduce
completely in the other! Consider
$\app{\abs{x}{\abs{y}{y}}}{\app{\abs{x}{\app{x}{x}}}{\abs{x}{\app{x}{x}}}}$ where
\[
\app{\abs{x}{\abs{y}{y}}}{\app{\abs{x}{\app{x}{x}}}{\abs{x}{\app{x}{x}}}}\larr\abs{y}{y}
\]
but
\begin{align*}
      &\app{\abs{x}{\abs{y}{y}}}{\app{\abs{x}{\app{x}{x}}}{\abs{x}{\app{x}{x}}}}\\
\lvrr &\app{\abs{x}{\abs{y}{y}}}{\app{\abs{x}{\app{x}{x}}}{\abs{x}{\app{x}{x}}}}\\
\lvrr &\cdots
\end{align*}
Historically at least, the call-by-name and call-by-value reduction regimes underlie the
distinction between so-called lazy and eager languages.

One final observation we should make about the \lc\ is which terms denote values. A value
should be, in a sense, irreducible and that criterion disqualifies applications from being
considered as values. A value should should not merely be a placeholder for arbitrary
values, and that criterion disqualifies lone variables from being considered as
values.\footnote{In actual fact, a value is an irreducible \lc\ term paired with an
environment which provides values for constituent free variables.} Thus, we shall consider
abstractions to be the sole form values can take in the \lc, habituating ourselves to the
idea that functions are data.

\chapter{\lv\ and \cm}

\section{\lv}

The \lv\ language is merely the call-by-value \lc.

Figure \ref{lv-language-forms} presents the language terms and evaluation contexts of \lv.
The definition of $e$ specifies the form of terms in \lv\ similar to our previous
discussion of the \lc. The definition of $E$ specifies evaluation contexts which, like
terms, are defined inductively. An evaluation context is either empty (denoted by
$\hole$), an application wherein the operator is being evaluated, or an application
wherein the operand is being evaluated.

\begin{figure}
\begin{align*}
E = &\app{E}{e} & e = &\app{e}{e}\\
    &\app{v}{E} &     &x\\
    &\hole      &     &v\\
    &           & v = &\abs{x}{e}
\end{align*}
\caption{\lv\ forms}
\label{lv-language-forms}
\end{figure}

Figure \ref{lv-language-semantics} presents the sole semantic definition of \lv, the
meaning of application.

\begin{figure}
\begin{align*}
E[(\lambda x.e)\,v]     &\rightarrow E[e[x\leftarrow v]]\\
\end{align*}
\caption{\lv\ evaluation rule}
\label{lv-language-semantics}
\end{figure}

\section{\cm}

We now consider an extension of \lv\ with facilities to manipulate continuation 
marks, introduced by Pettyjohn et al. \cite{pettyjohn2005continuations}, which 
we term \cm. As an extension of \lv, it inherits its definitions of language 
terms, evaluation contexts, and semantics.

Figure \ref{cm-language-forms} presents the syntactic forms of \cm.  Definitions of $E$
and $F$ signify evaluation contexts. The separation of $E$ from $F$ prevents $\wcm{v}{F}$
contexts from directly nesting within the entire evaluation context to enforce proper
tail-call behavior. The definition of $e$ is identical to that of \lv\ with the addition
of contionuation mark forms $\wcm{e}{e}$ and $\ccm$. (\cm\ expresses unkeyed marks which
obviates the need to specify a key to which a value will be associated. Hence, the
\scheme'wcm' and \scheme'ccm' forms need one parameter fewer than their Scheme
counterparts.)

\begin{figure}
\begin{align*}
E = &\wcm{v}{F} & e = &\app{e}{e}\\
    &F          &     &x\\
F = &\hole      &     &v\\
    &\app{E}{e} &     &\wcm{e}{e}\\
    &\app{v}{E} &     &\ccm\\
    &\wcm{E}{e} & v = &\abs{x}{e}
\end{align*}
\caption{\cm\ forms}
\label{cm-language-forms}
\end{figure}

Figure \ref{cm-language-semantics} presents the semantics of \cm\ in the form of a list of
reduction rules. Rule 1 defines the meaning of application as inherited from \lv. Rule 2
defines the tail behavior of the \scheme'wcm' form. Rule 3 expresses that the \scheme'wcm'
form takes on the value of its body. Finally, rule 4 defines the value of the \scheme'ccm'
form in terms of the $\chi$ metafunction.

\begin{figure}
\begin{align*}
E[(\lambda x.e)\,v]     &\rightarrow E[e[x\leftarrow v]]\tag{1}\\
E[\wcm{v}{\wcm{v'}{e}}] &\rightarrow E[\wcm{v'}{e}]\tag{2}\\
E[\wcm{v}{v'}]          &\rightarrow E[v']\tag{3}\\
E[\ccm]                 &\rightarrow E[\chi(E)]\tag{4}
\end{align*}
\caption{\cm\ semantics}
\label{cm-language-semantics}
\end{figure}

The definition of the $\chi$-metafunction is given in figure \ref{cm-chi-metafunction}.
Conceptually, the $\chi$-metafunction traverses the context from the outside in,
accumulating values as it encounters $\wcm{v}{E}$ contexts. Since the $\chi$ metafunction
is defined over evaluation contexts of \cm, its domain corresponds to the definitions of
$E$ and $F$ in figure \ref{cm-language-forms}.

\begin{figure}
\begin{align*}
\chi(\hole)             &= \mathrm{nil}\\
\chi(E[\app{\hole}{e}]) &= \chi(E)\\
\chi(E[\app{v}{\hole}]) &= \chi(E)\\
\chi(E[\wcm{\hole}{e}]) &= \chi(E)\\
\chi(E[\wcm{v}{\hole}]) &= v : \chi(E)
\end{align*}
\caption{Definition of $\chi$ metafunction}
\label{cm-chi-metafunction}
\end{figure}

% what are the contracts? why does it work?

% most states have a direct correspondence in C
% (E,e) being a state
% most behavior has a direct correspondence in C (evaluation steps)
% reinsertion of value, composition of contexts, semantic rules



In \cm, evaluation of an application form proceeds as

\begin{align*}
E[\app{e_0}{e_1}]\cmrr &E[\app{\hole}{e_1}][e_0]\\
                \cmrrs &E[\app{\hole}{e_1}][v_0]\\
                 \cmrr &E[\app{v_0}{e_1}]\tag{1}\\
                 \cmrr &E[\app{v_0}{\hole}][e_1]\\
                \cmrrs &E[\app{v_0}{\hole}][v_1]\\
                 \cmrr &E[\app{v_0}{v_1}]\tag{2}\\
                     = &E[\app{\abs{x}{e'_0}}{v_1}] &\text{for some $x$ and $e'_0$}\\
                 \cmrr &E[e'_0[x\leftarrow v_1]]\\
                     = &E[e_2] &\text{for some $e_2$}
\end{align*}

Steps 1 and 2 denote the insertion of a value into the hole in the context.

\chapter{CPS transformation}

\section{Introduction}

The CPS transform is actually a family of language transformations derived from Plotkin
\cite{plotkin1975call} designed to simplify  programs by representing all data and control
flow uniformly and explicitly. This, in turn, simplifies compiler construction and
analyses such as optimization and verification \cite{sabry1994formal}. The standard
variation of CPS adds a formal parameter to every function definition and an argument to
every call site.

As an example, consider once again the two variants of the factorial function, sans
continuation marks, given earlier. In CPS, the properly-recursive variant can be expressed
as
\begin{schemedisplay}
(define (fac n k) 
  (if (= n 0)
      (k 1)
      (fac (- n 1) (lambda (acc) (k (* n acc))))))
\end{schemedisplay}
and the tail-recursive variant as
\begin{schemedisplay}
(define (fac-tr n acc k)
  (if (= n 0)
      (k acc)
      (fac-tr (- n 1) (* n acc) k)))
\end{schemedisplay}
(For clarity, we have treated ``primitive'' functions--equality comparison, subtraction,
and multiplication--in a direct manner. In contrast, a comprehensive CPS transformation
would affect \emph{every} function.)

Notice that, in the first variation, each recursive call receives a newly-constructed
\scheme{k} encapsulating additional work to be performed at the completion of the
recursive computation. In the second, \scheme{k} is passed unmodified, so while
computation occurs within each context, no \emph{additional} computation pends. From this
example, we see that the CPS representation is ideal for understanding tail-call behavior
as it is explicit that the continuation is preserved by the tail call.

The purpose of CPS does not lie solely in pedagogy, however. The reification of and
consequent ability to directly manipulate the continuation is powerful, analogous in power
to the ability to \emph{capture} a continuation which some languages provide. In Scheme,
this is accomplished with \scheme{call/cc}, short for ``call with current continuation''.
This call takes one argument which itself is a function of one argument. \scheme{call/cc}
calls its argument, passing in a functional representation of the current
continuation--the continuation present when \scheme{call/cc} was invoked. This
continuation function takes one argument which is treated as the result of
\scheme{call/cc} and runs this continuation to completion.

As a simple example,
\begin{schemedisplay}
(+ 1 (call/cc
       (lambda (k)
         (k 1))))
\end{schemedisplay}
returns \scheme'2'. In effect, invoking \scheme{k} with \scheme'1' is the same 
as replacing the entire \scheme{call/cc} invocation with \scheme'1'.

Much of the power of \scheme{call/cc} lies in the manifestation of the continuation as a
function, giving it first-class status. It can be passed as an argument in function calls,
invoked, and, amazingly, reinvoked at leisure. It is this reinvokeability that makes
\scheme{call/cc} the fundamental unit of control from which all other control structures can
be built, including generators, coroutines, and threads.

%\emph{call/cc} is erroneously seen as incredibly heavyweight and overkill for control
%(cite something). This conception probably comes from the conceptualization of the
%continuation as the call stack and continuation capture as stack copy while continuation
%call is stack installation. It is also seen as a form of \emph{goto} which is known to
%obfuscate control flow and impede analysis (cite something). [Can't and shouldn't talk
%much about the second. Probably take it out.] Bearing in mind that the CPS transformation
%aids compilers, it is useful to investigate the characterization of \emph{call/cc} within
%the standard CPS transformation.

In direct style, the definition of \scheme{call/cc} is conceptually 
\begin{schemedisplay}
(define call/cc
  (lambda (f)
    (f (get-function-representing-continuation))))
\end{schemedisplay}
where \scheme{get-function-representing-continuation} is an opaque function which leverages
sweeping knowledge of the language implementation. The CPS definition is notably simpler:
\begin{schemedisplay}
(define call/cc
  (lambda (f k)
    (f (lambda (x w) (k x)) k)))
\end{schemedisplay}

Variations on the standard CPS transformation can make the expression of certain control
structures more straightforward. For instance, the ``double-barrelled'' CPS transformation
is a variation wherein each function signature receives not one but two additional formal
parameters, each a continuation. One application of this particular variation is error
handling with one continuation argument representing the remainder of a successful
computation and the other representing the failure contingency. It is especially useful in
modelling exceptions and other non-local transfers of control in situations where the
computation might fail. In general, the nature of the CPS transformation allows it to
untangle complicated, intricate control structures.

Similar transformations exist which express other programming language features such as
security annotations \cite{wallach2000safkasi} and control structures such as procedures,
exceptions, labelled jumps, coroutines, and backtracking. On top of other offerings, this
places it in a category of tools to describe and analyze programming language features.
(This category is also occupied by Moggi's computational \lc--monads
\cite{moggi1989computational}.)

\section{Example}

We will now focus our attention on a CPS transform defined over \lv.

A CPS transformation is a global syntactic transformation of language terms. Recall that
terms in the \lc\ take the form of lone variables $x$, $\lambda$-abstractions
$\abs{x}{M}$, and applications $\app{M}{N}$ where $M$ and $N$ are themselves \lc\ terms. A
comprehensive CPS transform definition then need only specify transformations for these
three categories. As an example, consider Fischer's CPS transform \cite{fischer1972lambda}:
\begin{align*}
\mathcal{F}[x]          &= \abs{k}{\app{k}{x}}\\
\mathcal{F}[\abs{x}{M}] &= \abs{k}{\app{k}{\abs{x}{\mathcal{F}[M]}}}\\
\mathcal{F}[\app{M}{N}] &= \abs{k}{\app{\mathcal{F}[M]}{\abs{m}{\app{\mathcal{F}[N]}{\abs{n}{\app{\app{m}{n}}{k}}}}}}
\end{align*}
Fischer's CPS transform abstracts each term in the \lc: lone variables wait on a
continuation, abstractions receive a degree of indirection, and even applications, the
sole reduction facility of the \lc, become abstractions. In essence, terms become
suspended in wait of a continuation argument. By priming a term so-transformed with a
continuation function--even as simple as the identity function--we instigate a cascade of
computation.

GO OVER THE REST OF THIS SECTION

In the case of lone variables and applications, this transformation ultimately has no
effect on the result of the computation. However, abstractions, the values of the
\lc, are contaminated by the transform. For example, consider the
transformation of $\lambda x.x$
\begin{align*}
\mathcal{F}[\lambda x.x] &= \lambda k.k\,(\lambda x.\mathcal{F}[x])\\
                         &= \lambda k.(k\,\lambda x.\lambda k.(k\,x))
\end{align*}
If we apply this term to the identity function, it reduces as
\begin{align*}
                        &\lambda k.(k \lambda x.\lambda k.(k\,x))\,\lambda y.y\\
\lvrr &\lambda y.y\,\lambda x.\lambda k.(k\,x)\\
\lvrr &\lambda x.\lambda k.(k\,x)
\end{align*}
The result of this reduction, in common with most others, contains residual terms from the
CPS transform. We will need to account for this particular property of Fischer's CPS
transform.

One of the many reasons continuation-passing style is useful is that is allows evaluation
order to be controlled. In fact, Plotkin \cite{plotkin1975call} showed that it can be used
to simulate the call-by-value \lc\ with the call-by-name \lc
and vice versa. We can show that, in the call-by-value \lc, the passed
continuation is applied only to fully-reduced terms. This can be done by verifying this
property for each case of the CPS transform definition. Before doing so, we remind that no
reduction is performed by effect of the transformation.
\[
T[x]=\lambda k.(k\,x)
\]
Variables are irreducible, so the property holds immediately here.
\[
T[\lambda x.E]=\lambda k.(k\,\lambda x.T[E])
\]
Here we reason inductively by assuming that the property holds for E. Abstractions are
irreducible in a call-by-value regime, so the property holds in this case also.
\[
T[E\,F]=\lambda k.(T[E]\,\lambda e.(T[F]\,\lambda f.((e\,f)\,k))))
\]
In this case, we observe that the continuation $k$ provided is not directly applied.
Instead, the operator is evaluated and a continuation is constructed into which its value
may be passed. The operand is treated similarly. Finally, the operator is applied to the
operand and $k$ is not invoked but passed to the result.

Notice that $k$, which represents the rest of the continuation, is passed unmodified.
Specifically, a new continuation which employs $k$ as a subcontinuation has not been
constructed. This quality is characteristic of a tail call in which the evaluation context
for the arguments, no longer necessary, is subsumed by the evaluation context of the newly
formed application.

Finally, we observe that every transformed application passes--rather than invokes--the
provided continuation and that occurs only after reduction. Then continuations can be
invoked only as in the cases of variables and abstractions and we can see that they are 
only applied to fully-reduced terms.

\setspecialsymbol{e_0}{$e_0$}
\setspecialsymbol{e_0p}{$e'_0$}
\setspecialsymbol{Ce_0}{$\C{e_0}$}
\setspecialsymbol{Ce_0p}{$\C{e'_0}$}
\setspecialsymbol{e_1}{$e_1$}
\setspecialsymbol{Ce_1}{$\C{e_1}$}
\setspecialsymbol{Ce_1p}{$\C{e'_1}$}
\setspecialsymbol{Cv}{$\C{v}$}
\setspecialsymbol{v_0}{$v_0$}
\setspecialsymbol{Cv_0}{$\C{v_0}$}
\setspecialsymbol{Cv_0p}{$\C{v'_0}$}
\setspecialsymbol{Cpv_0}{$\Cp{v_0}$}
\setspecialsymbol{Cpv_1}{$\Cp{v_1}$}
\setspecialsymbol{v_1}{$v_1$}
\setspecialsymbol{T}{$\mathcal{A}$}
\setspecialsymbol{C}{$\mathcal{C}$}
\setspecialsymbol{Cp}{$\mathcal{C}'$}
\setspecialsymbol{Ch}{$\hat{\mathcal{C}}$}
\setspecialsymbol{Ccps}{$\mathcal{C}_{\mathrm{cps}}$}
\setspecialsymbol{Cpcps}{$\mathcal{C}'_{\mathrm{cps}}$}
\setspecialsymbol{Chcps}{$\hat{\mathcal{C}}_{\mathrm{cps}}$}
\setspecialsymbol{hole}{$\hole$}
\setspecialsymbol{bottom}{$\perp$}
\setspecialsymbol{Ce_0p_x_Cpv_1}{$\C{e'_0}[x\leftarrow\Cp{v_1}]$}
\setspecialsymbol{e_0p_x_v_1}{$e'_0[x\leftarrow v_1]$}
\setspecialsymbol{Cz}{$\C{z}$}
\setspecialsymbol{CE}{$\C{E}$}
\setspecialsymbol{xiE}{$\xi(E)$}
\setspecialsymbol{chiE}{$\chi(E)$}
\setspecialsymbol{CchiE}{$\C{\chi(E)}$}

\chapter{$\mathcal{C}$}

A CPS-like global transformation can compile the \lc\ with continuation marks into
the plain \lc\ in a semantics-preserving way.

In order to demonstrate this, we must first clarify (and later, formalize) the
semantics-preservation property. By this, we mean that the transformation commutes with
evaluation. Call a satisfactory transformation $\mathcal{C}$. Then $\mathcal{C}$ satisfies 
\[
\begin{array}{ccc}
p & \cmrrs & v\\
\downarrow_\mathcal{C} & & \downarrow_\mathcal{C}\\
\C{p} & \lvrrs & \C{v}
\end{array}
\]
for any program $p\in\lambda_{cm}$.

The burden of demonstration is then reduced to the existence of $\mathcal{C}$. We do this by construction.

\subsection{Intuition}

The essence of \cm\ is that programs can apply information to and observe information about the context in which they are evaluated. Programs in \lv\ have no such facility. We can simulate this facility by explicitly passing contextual information to each term as it is evaluated. We can define $\mathcal{C}$ to transform \scheme'wcm' directives to manipulate this information and \scheme'ccm' directives to access it. Intuitively, we can transform \cm\ programs to mark-passing style.

However, marks alone do not account for the tail-call behavior specified by rule \ref{tail-enforce}. Since tail-call behavior is observable (if indirectly) by \cm\ programs, we must also provide to each term information about the position in which it is evaluated. Specifically, each transformed \scheme'wcm' directive must be notified whether it is evaluated in tail position of an enclosing \scheme'wcm' directive as it must behave specially if so. Thus, in addition to passing the current continuation marks, the transform should pass a flag to each term indicating whether it is evaluated in tail position of a \scheme'wcm' directive.

%Since this is a dynamic property of the evaluation, we do not attempt to infer it statically.

These two pieces of information suffice to correctly simulate continuation marks.

\subsection{Concept}

The definition of $\mathcal{C}$ entails transformation over each syntactic form of \cm.

With this in mind, consider a conceptual transformation of application, \scheme|C[(rator-expr rand-expr)]|, as
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    (let ((rator-value ((C[rator-expr] FALSE) marks))
          (rand-value ((C[rand-expr] FALSE) marks))
      (((rator-value rand-value) flag) marks))))
\end{schemedisplay}
ignoring for the moment that \scheme'let' is in neither \lv\ or \cm. This definition captures that
\begin{enumerate}
\item before evaluation, we expect \scheme'flag' to indicate tail position information and \scheme'marks' to provide a list of the current continuation marks,
\item we would like to evaluate \scheme'C[rator-expr]' and \scheme'C[rand-expr]' in the same manner, providing to each its contextual information--specifically that neither is evaluated in tail position of a \scheme'wcm' directive and the continuation marks for each are unchanged from the parent context,
\item and, following evaluation of operator and operand and application, evaluation of the resultant term is performed with the original contextual information.
\end{enumerate}

Now consider a conceptual transformation of a \scheme'wcm' directive, \scheme|C[(wcm mark-expr body-expr)]|, as
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    ((C[body-expr] TRUE) (let ((mark-value ((C[mark-expr] FALSE) marks))
                               (rest-marks (if flag (snd marks) marks)))
                           (cons mark-value rest-marks)))))
\end{schemedisplay}
with similar caveats as the previous case. This definition captures that
\begin{enumerate}
\item as in application, we expect \scheme'flag' to indicate tail position information and \scheme'marks' to provide a list of the current continuation marks,
\item we evaluate \scheme'mark-expr' with correct contextual information,
\item we discard the first continuation mark of the parent context if evaluation is occurring in tail position of a \scheme'wcm' directive,
\item and we evaluate \scheme'C[body-expr]' with the correct tail-position flag and current continuation marks.
\end{enumerate}

Finally, consider the conceptual transformation of a \scheme'ccm' directive, \scheme|C[(ccm)]|, as
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    marks))
\end{schemedisplay}
wherein we reap the fruits of simplicity from our laborious passing: this definition is gratifyingly direct.

The conceptual transformation of variables \scheme'x' and values \scheme'(lambda (x) e)' is straightforward.

We now address the absence of \scheme'let', \scheme'if', \scheme'cons', etc. from \lv.

We can express the \scheme'let' construct in \lv\ with application. An expression such as
\begin{schemedisplay}
(let ((x_1 e_1)
      ...
      (x_n e_n))
  e)
\end{schemedisplay}
can be interpreted as
\begin{schemedisplay}
(...((lambda (x_1) ... (lambda (x_n)
           e)...) e_1) ...) e_n)
\end{schemedisplay}
which is the curried form of
\begin{schemedisplay}
((lambda (x_1 ... x_n)
           e) e_1 ... e_n)
\end{schemedisplay}
We unfold this characterization of \scheme'let' to guide the construction of $\mathcal{C}$ before simplifying.
[Drop everything after ``with application.''?]

To achieve \scheme'if' and conditionals as well as list primitives \scheme'cons', \scheme'snd', and \scheme'nil', we use the Church encodings of fig. \ref{church-encodings}.

\subsection{Initiation}

Abstracting terms has the effect of suspending evaluation. When an entire program is transformed, all evaluation is suspended, and awaits arguments representing contextual information. At the top level, the context is empty, so we pass the contextual information for the empty context: \scheme'FALSE', indicating evaluation is \emph{not} occurring in \scheme'wcm' tail position and \scheme'NIL', an empty list of marks.

We can accommodate this by defining a top-level transform $\hat{\mathcal{C}}$ in terms of $\mathcal{C}$ by
\begin{equation}
\Ch{p}=\app{\app{\C{p}}{\false}}{\nil}
\end{equation}

and stating our commutativity property as
\begin{equation}
\label{commutativity-property}
\Ch{\evalcm{p}}=\evalv{\Ch{p}}
\end{equation}
which is equivalent to
\begin{equation}
\app{\app{\C{\evalcm{p}}}{\false}}{\nil}=\evalv{\app{\app{\C{p}}{\false}}{\nil}}
\end{equation}

\subsection{Some Final Subtleties}

Our choice to keep the core language small by omitting lists as primitive values has the consequence of complicating our transform somewhat. Because lists are defined in terms of \lc\ values which are themselves touched by the transform and because of the commutativity property that $\mathcal{C}$ must satisfy, we cannot deal with a list of continuation marks directly--we must instead deal with a transformed list of transformed continuation marks, and manipulation of this list within transformed terms must occur at the transformed level.

Additionally, after evaluation, values are ``truncated'' with their leading abstractions applied away. For instance, the transformation of the value \scheme|(lambda (x) x)| to \scheme|(lambda (flag) (lambda (marks) (lambda (x) (lambda (flag) (lambda (marks) x)))))| will yield, following evaluation, \scheme|(lambda (x) (lambda (flag) (lambda (marks) x)))|. For convenience, we define 
\begin{equation}
\Cp{\abs{x}{e}}=\abs{x}{\C{e}}
\end{equation}
and we adjust $\hat{\mathcal{C}}$ so that
\begin{equation}
\Ch{p}=\app{\app{\C{p}}{\false}}{\Cp{\nil}}
\end{equation}


\theoremstyle{definition}
\newtheorem{case}{Case}
\newtheorem{defn}{Definition}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\newenvironment{schemedefn}[1]{\begin{defn}#1}{\end{defn}}
\newenvironment{namedschemedefn}[2]{\begin{defn}\label{#1}$#2$}{\end{defn}}

\subsection{Definition of $\mathcal{C}$}

Finally, we present the definition of $\mathcal{C}$ over the five syntactic forms of \cm.


\begin{schemedefn}{\scheme|C[(rator-expr rand-expr)]|}

The formal transformation of application follows the \scheme'let' version exactly except the definitions of \scheme'rator-value' and \scheme'rand-value' are folded directly in.
\begin{schemedisplay}
(lambda (flags)
  (lambda (marks)
    (((((C[rator-expr] FALSE) marks)
       ((C[rand-expr] FALSE) marks))
      flags)
     marks)))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|C[(wcm mark-expr body-expr)]|}

The formal transformation of a \scheme'wcm' directive is also extremely similar to the \scheme'let' version. The definition of \scheme'C[cons]' is unfolded and simplified.
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    ((C[body-expr] TRUE)
     (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)])))
       ((C[mark-expr] FALSE) marks))
      ((flag Ch[(SND marks)]) marks)))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|C[(ccm)]|}

The \scheme'let' version of the transformation of a \scheme'ccm' directive remains unchanged.
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    marks))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|C[v]|=\scheme|C[(lambda (x) e)]|}

Like other terms, values are modified to receive contextual information. However, being unaffected by context, values discard this information.
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    (lambda (x) C[e])))
\end{schemedisplay}
\end{schemedefn}


\begin{schemedefn}{\scheme|C[x]|}

Variables have the property that, when substitution occurs, they reconstitute transformed values. That is, in the midst of application in $\mathcal{C}$, terms of the form \scheme|(Cp[(lambda (x) x)] Cp[(lambda (y) y)])| appear, reducing to $\C{x}[x\leftarrow \Cp{\abs{y}{y}}]=\C{x[x\leftarrow\abs{y}{y}}=\C{\abs{y}{y}}$.
\begin{schemedisplay}
(lambda (flag)
  (lambda (marks)
    x))
\end{schemedisplay}
\end{schemedefn}

\subsection{Definition of $\mathcal{C}$ in CPS}

Many compilers transform source to continuation-passing style (CPS) in the compilation process. The use of CPS as an intermediate language enables a host of optimization analyses and makes the implementation of otherwise-heavyweight features trivial, such as first-class continuations \cite{appel2007compiling}.

We present a continuation mark transformation integrated in CPS.

\begin{schemedefn}{\scheme|Ccps[(rator-expr rand-expr)]|}
\begin{schemedisplay}
(lambda (kont)
   (lambda (flag)
     (lambda (marks)
       (((Ccps[rator-expr]
          (lambda (rator-value)
            (((Ccps[rand-expr]
               (lambda (rand-value)
                 ((((rator-value rand-value) kont) flag) marks)))
              FALSE)
             marks)))
         FALSE)
        marks))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|C[(wcm mark-expr body-expr)]|}
\begin{schemedisplay}
(lambda (kont)
  (lambda (flag)
    (lambda (marks)
      (((Ccps[mark-expr]
          (lambda (mark-value) 
            ((lambda (rest-marks) 
               (((Ccps[body-expr] kont) TRUE) Cp[((CONS mark-value) rest-marks)])))
             ((flag Ch_cps[(SND marks)]) marks))))
        FALSE)
       marks))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|Ccps[(ccm)]|}
\begin{schemedisplay}
(lambda (kont)
  (lambda (flag)
    (lambda (marks)
      (kont marks))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|Ccps[v]|=\scheme|Ccps[(lambda (x) e)]|}
\begin{schemedisplay}
(lambda (kont)
  (lambda (flag)
    (lambda (marks)
      (kont (lambda (x) Ccps[e])))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|Ccps[x]|}
\begin{schemedisplay}
(lambda (kont)
  (lambda (flag)
    (lambda (marks)
      (kont x))))
\end{schemedisplay}
\end{schemedefn}

We include corresponding definitions for $\mathcal{C}'$ and $\hat{\mathcal{C}}$.

\begin{schemedefn}{\scheme|Cpcps[(lambda (x) e)]|}
\begin{schemedisplay}
(lambda (x) Ccps[e])
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\scheme|Chcps[p]|}
\begin{schemedisplay}
(((Ccps[p] (lambda (x) x)) FALSE) Cpcps[nil])
\end{schemedisplay}
\end{schemedefn}

\subsection{Example}

Consider the \cm\ program \scheme|(wcm 0 ((lambda (x) (wcm x (ccm))) 1))| which reduces as
\begin{schemedisplay}
(wcm 0 ((lambda (x) (wcm x (ccm))) 1))
(wcm 0 (wcm 1 (ccm)))
(wcm 1 (ccm))
(wcm 1 (lambda (z) ((z 1) (lambda (x) (lambda (y) y)))))
(lambda (z) ((z 1) (lambda (x) (lambda (y) y))))
\end{schemedisplay}
and transforms as
\begin{schemedisplay}
Ch[(wcm 0 ((lambda (x) (wcm x (ccm))) 1))]

((C[(wcm 0 ((lambda (x) (wcm x (ccm))) 1))] FALSE) Cp[NIL])

(((lambda (flag)
    (lambda (marks)
      ((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
       (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
         ((C[0] FALSE) marks)) ((flag Ch[(SND marks)]) marks)))))
  FALSE) Cp[NIL])

((lambda (marks)
   ((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
    (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
      ((C[0] FALSE) marks)) ((FALSE Ch[(SND marks)]) marks))))
 Cp[NIL])

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((C[0] FALSE) Cp[NIL])) ((FALSE Ch[(SND NIL)]) Cp[NIL])))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   (((lambda (flag) (lambda (marks) 0)) FALSE) Cp[NIL])) ((FALSE Ch[(SND NIL)]) Cp[NIL])))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((lambda (marks) 0) Cp[NIL])) ((FALSE Ch[(SND NIL)]) Cp[NIL])))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   0) ((FALSE Ch[(SND NIL)]) Cp[NIL])))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 ((lambda (rest-marks) Cp[((CONS 0) rest-marks)])
  ((FALSE Ch[(SND NIL)]) Cp[NIL])))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE)
 ((lambda (rest-marks) Cp[((CONS 0) rest-marks)])
  Cp[NIL]))

((C[((lambda (x) (wcm x (ccm))) 1)] TRUE) Cp[((CONS 0) NIL)])

(((lambda (flag)
    (lambda (marks)
      (((((C[(lambda (x) (wcm x (ccm)))] FALSE) marks)
         ((C[1] FALSE) marks))
        flag)
       marks))) TRUE) Cp[((CONS 0) NIL)])

(((((C[(lambda (x) (wcm x (ccm)))] FALSE) Cp[((CONS 0) NIL)])
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

((((((lambda (flag) (lambda (marks) (lambda (x) C[(wcm x (ccm))]))) FALSE) Cp[((CONS 0) NIL)])
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

(((((lambda (marks) (lambda (x) C[(wcm x (ccm))])) Cp[((CONS 0) NIL)])
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

((((lambda (x) C[(wcm x (ccm))])
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

((((lambda (x) C[(wcm x (ccm))])
   (((lambda (flag) (lambda (marks) 1)) FALSE) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

((((lambda (x) C[(wcm x (ccm))])
   ((lambda (marks) 1) Cp[((CONS 0) NIL)]))
  TRUE) Cp[((CONS 0) NIL)])

((((lambda (x) C[(wcm x (ccm))])
   1) TRUE) Cp[((CONS 0) NIL)])

((C[(wcm 1 (ccm))]
   TRUE) Cp[((CONS 0) NIL)])

(((lambda (flag)
    (lambda (marks)
      ((C[(ccm)] TRUE)
       (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
         ((C[1] FALSE) marks))
        ((flag Ch[(SND marks)]) marks)))))
  TRUE) Cp[((CONS 0) NIL)])

((lambda (marks)
   ((C[(ccm)] TRUE)
    (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
      ((C[1] FALSE) marks))
     ((TRUE Ch[(SND marks)]) marks))))
 Cp[((CONS 0) NIL)])

((C[(ccm)] TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

(((lambda (flag) (lambda (marks) marks))
  TRUE)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((C[1] FALSE) Cp[((CONS 0) NIL)]))
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   (((lambda (flag) (lambda (marks) 1)) FALSE) Cp[((CONS 0) NIL)]))
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   ((lambda (marks) 1) Cp[((CONS 0) NIL)]))
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 (((lambda (mark-value) (lambda (rest-marks) Cp[((CONS mark-value) rest-marks)]))
   1)
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 ((lambda (rest-marks) Cp[((CONS 1) rest-marks)])
  ((TRUE Ch[(SND ((CONS 0) NIL))]) Cp[((CONS 0) NIL)])))

((lambda (marks) marks)
 ((lambda (rest-marks) Cp[((CONS 1) rest-marks)])
  Ch[(SND ((CONS 0) NIL))]))

((lambda (marks) marks)
 ((lambda (rest-marks) Cp[((CONS 1) rest-marks)])
  Cp[NIL]))

((lambda (marks) marks)
 Cp[((CONS 1) NIL)])

Cp[((CONS 1) NIL)]
\end{schemedisplay}

[This example is way too long. Are trivial examples generally uninteresting?]

\chapter{Testing}

We do not attempt to construct a correct transformation \emph{ex nihilo}. A pragmatic
approach to the discovery of a correct transformation involves consistent feedback and
testing to validate candidate transforms. Testing is no substitute for proof, but, as
Klein et al. \cite{klein2012run} show, proof is no substitute for testing. Lightweight
mechanization is a fruitful middle ground between pencil-and-paper analysis and fully-
mechanized formal proof. We use Redex to provide feedback, thoroughly exercise candidates,
and perform exploratory analysis.

\section{Redex}

Redex \cite{findler2010redex} is a domain-specific language for exploring language
semantics. It lives very close to the semantics notation we have used so far in this
discussion.

\subsection{Toy Language}
To illustrate how easily langagues can be defined in Redex, we will examine a Redex
program which defines a toy language. In contrast to a Redex tutorial, we will not concern
ourselves with the syntax and structure of roads not taken and will instead briefly
explain each component of the program.

\setkeyword{define-language define-extended-language variable-not-otherwise-mentioned number reduction-relation extend-reduction-relation in-hole substitute term define-metafunction define-metafunction/extension reduces-to-one-value? value? redex-match length apply-reduction-relation* first redex-check}
\setconstant{toy toy-rr undefined hole}
\setspecialsymbol{-->}{$\rightarrow$}
\begin{singlespace}
\begin{schemedisplay}
(define-language toy
  (x variable-not-otherwise-mentioned)
  (v number undefined) 
  (e (+ e e) (with (x e) e) x v)
  (E hole (+ E e) (+ v E) (with (x E) e)))
\end{schemedisplay}
\end{singlespace}

This expression defines the abstract syntactic structure of a language named \emph{toy}.
There are four categories of structures: \scheme'x', \scheme'v', \scheme'e', and
\scheme'E'. The category \scheme'x' is defined to contain any token not otherwise
mentioned in the definition. The category \scheme'v' is defined to contain numbers and the
token \scheme{undefined}. The category \scheme'e' is defined to contain the expression
forms of the language, of which there are four: addition expressions, \scheme{with}
expressions, lone variables, and lone values. The last category, \scheme'E', does not
define abstract syntax but instead reduction contexts. The first reduction context is a
\scheme{hole} (a special token in Redex) which will be filled in with the result of the
expression that previously resided in its place. The next two are addition contexts, the
first representing the evaluation of the first argument and the second representing the
evaluation of the second; the composition of these contexts imposes an order on the
evaluation of the arguments. The final context, a \scheme{with} context, specifies a
variable, a value, and an expression within which that variable is bound to that value.

\begin{singlespace}
\begin{schemedisplay}
(define toy-rr
  (reduction-relation toy
   (--> (in-hole E (+ number_1 number_2))
        (in-hole E (+ (term number_1) (term number_2)))
        "+")
   (--> (in-hole E (with (x_1 v_1) e_1))
        (in-hole E (substitute x_1 v_1 e_1))
        "with")
   (--> (in-hole E x_1)
        (in-hole E undefined)
        "free variable")
   (--> (in-hole E (+ undefined e_1))
        (in-hole E undefined)
        "undefined in first position")
   (--> (in-hole E (+ number_1 undefined))
        (in-hole E undefined)
        "undefined in second position")))
\end{schemedisplay}
\end{singlespace}

This term defines a reduction relation on the \scheme{toy} language. The five defined
reductions, signalled by \scheme{-->}, match specified patterns and manipulate them
according to the defined rules. These define: the addition of two numbers; the
substitution of a \scheme{with} expression; a lone variable; the addition of an undefined
value on the left; and the addition of an undefined value on the right.

\begin{singlespace}
\begin{schemedisplay}
(define-metafunction toy
  substitute : x v e -> e
  [(substitute x_1 v_1 (+ e_1 e_2))
   (+ (substitute x_1 v_1 e_1) (substitute x_1 v_1 e_2))]
  [(substitute x_1 v_1 (with (x_1 e_1) e_2))
   (with (x_1 (substitute x_1 v_1 e_1)) e_2)]
  [(substitute x_1 v_1 (with (x_2 e_1) e_2))
   (with (x_2 (substitute x_1 v_1 e_1)) (substitute x_1 v_1 e_2))]
  [(substitute x_1 v_1 x_1)
   v_1]
  [(substitute x_1 v_1 x_2)
   x_2]
  [(substitute x_1 v_1 v_2)
   v_2])
\end{schemedisplay}
\end{singlespace}

The definition of the \scheme{with} reduction rule relies on the \scheme{substitute}
metafunction. (The language used to define \scheme'toy' (Redex) is the metalanguage. 
As functions are in the language, metafunctions are in the metalanguage.) The
\scheme{substitute} metafunction recursively substitutes a variable in an expression with
a value. The substitution is only propagated as long as a binding with the same name is
not encountered. At that point, the substitution is performed in the value expression of
the binding, but not the body. This allows for expressions like
\begin{singlespace}
\begin{schemedisplay}
(with (x 5)
  (with (x x)
    x))
\end{schemedisplay}
\end{singlespace}
to behave as we expect (returning \scheme'5').

\subsubsection{Testing}

Now that the syntactic forms and reduction rules of the language are defined, we can use 
the randomized testing built into Redex to investigate properties of the language. We 
start by defining the helper function 
\begin{singlespace}
\begin{schemedisplay}
(define (reduces-to-one-value? e)
  (let ((results (apply-reduction-relation* toy-rr e)))
    (and (= (length results) 1)
         (value? (first results)))))
\end{schemedisplay}
\end{singlespace}
which has its own helper function 
\begin{singlespace}
\begin{schemedisplay}
(define value? (redex-match toy v))
\end{schemedisplay}
\end{singlespace}
The \scheme{*} at the end of the function name \scheme{apply-reduction-relation*}
signifies that all possible reduction rules will be applied as many times as possible. If
some of the reduction rules don't actually reduce terms, the relation may produce a
reducible term indefinitely. The function \scheme{apply-reduction-relation*} is in a sense
strict in the reduction relation and will likewise run indefinitely if this is the case.

After the language and some properties have been established, the randomized testing, 
initiated by
\begin{schemedisplay}
(redex-check toy e (reduces-to-one-value? (term e)))
\end{schemedisplay}
is simple. We merely provide the name of the language we wish to work with, the
nonterminal in the grammar we wish to use to generate language terms, and a predicate that
checks terms for properties. This function generates terms gradually increasing in size,
applying the predicate to each in turn, and terminates with a counterexample or after a
set number of terms have been checked (1000 by default).

\subsubsection{Proof}

Randomized testing can increase our confidence in various assertions but is no substitute 
for proof. We express the property of reducing to one value with the following theorem:

\newtheorem*{toythm}{Toy Language One-Value Theorem}
\begin{toythm}
For all terms \scheme'e' of the toy language, \scheme'e' reduces to exactly one
value.\footnote{We do not use the term \emph{value} loosely here; the toy language
definition specifies what constitute values, and we appeal to this.}
\end{toythm}
We proceed by induction on the structure of terms \scheme'e' of the toy language. First,
we consider the base cases.
\begin{proof}[Case \scheme'v']
A term \scheme'e' of the form \scheme'v' is exactly one value and cannot be reduced, 
so the statement holds.
\end{proof}
\begin{proof}[Case \scheme'x']
A term \scheme'e' of the form \scheme'x', a variable, reduces to \scheme{undefined}, 
a value term, so the statement holds.
\end{proof}
\begin{proof}[Case \scheme|(with (x e_1) e_2)|]
By induction, we assume that \scheme{e_1} reduces to exactly one value. Then the
``with''-rule can only be applied once, resulting in a single term \scheme{e_2} in
\scheme'e' which, by our inductive hypothesis, reduces to only one value.
\end{proof}
\begin{proof}[Case \scheme|(+ e_1 e_2)|]
By induction, we assume both \scheme{e_1} and \scheme{e_2} reduce to a single value. We
consider two subcases: If \scheme{e_1} reduces to \scheme{undefined}, the ``undefined in
first position''-rule is applied, and the whole term reduces to \scheme{undefined}. If
\scheme{e_1} reduces to a number, we consider two further subcases: If \scheme{e_2}
reduces to a number, the ``+''-rule is applied, and the entire expression reduces to the
sum of the two numbers obtained. If \scheme{e_2} reduces to \scheme{undefined}, the
``undefined in second position''-rule is applied, and the entire term reduces to
\scheme{undefined}. Thus, in all subcases, the whole term reduces to exactly one value.
\end{proof}

This property is fairly trivial and its proof is similarly trivial, but it is a shadow of 
the approach we will ultimately take to verify certain transformation properties.

\setspecialsymbol{lambda}{$\lambda$}
\setspecialsymbol{-->}{$\rightarrow$}
\setspecialsymbol{betav}{$\beta$v}
\setconstant{error}
\setkeyword{subst}
\setkeyword{chi}

\section{Flavors of $\lambda$}

Our first task in developing a testing environment for transformations is to define interpreters for \cm\ and \lv.

We begin with \lv, the simpler language.

\subsection{\lv}

\setspecialsymbol{lambdav}{$\lambda$v}
\setspecialsymbol{lambdav-rr}{$\lambda$v-rr}
\setspecialsymbol{lambdav-subst}{$\lambda$v-subst}

To begin, we define language terms and evaluation contexts.

\begin{singlespace}
\begin{schemedisplay}
(define-language lambdav
  (e (e e) x v error)
  (x variable-not-otherwise-mentioned)
  (v (lambda (x) e))
  (E (E e) (v E) hole))
\end{schemedisplay}
\end{singlespace}

The characterization of \lv\ seen in figures \ref{lv-language-forms} and
\ref{lv-language-semantics} was influenced by the knowledge that an interpreter would need
to be built. Because Redex lives so close to this characterization, the only change we
make in translation is the addition of \scheme'error'.

\begin{singlespace}
\begin{schemedisplay}
(define lambdav-rr
  (reduction-relation lambdav
   (--> (in-hole E ((lambda (x) e) v))
        (in-hole E (lambdav-subst x v e))
        "betav")
   (--> (in-hole E x)
        (in-hole E error)
        "error: unbound identifier")
   (--> (in-hole E (error e))
        (in-hole E error)
        "error in operator")
   (--> (in-hole E (v error))
        (in-hole E error)
        "error in operand")))
\end{schemedisplay}
\end{singlespace}

The first rule in the reduction relation corresponds with the sole semantic rule found in \ref{lv-language-semantics}. The remaining handle cases introduced by \scheme'error'.

\begin{singlespace}
\begin{schemedisplay}
(define-metafunction lambdav
  lambdav-subst : x v e -> e
  ;; 1. substitute in application
  [(lambdav-subst x_1 v_1 (e_1 e_2))
   ((lambdav-subst x_1 v_1 e_1) (lambdav-subst x_1 v_1 e_2))]
  ;; 2a. substitute in variable (same)
  [(lambdav-subst x_1 v_1 x_1)
   v_1]
  ;; 2b. substitute in variable (different)
  [(lambdav-subst x_1 v_1 x_2)
   x_2]
  ;; 3a. substitute in abstraction (bound)
  [(lambdav-subst x_1 v_1 (lambda (x_1) e_1))
   (lambda (x_1) e_1)]
  ;; 3b. substitute in abstraction (free)
  [(lambdav-subst x_1 v_1 (lambda (x_2) e_1))
   (lambda (x_2) (lambdav-subst x_1 v_1 e_1))]
  ;; 4. substitute in error
  [(lambdav-subst x_1 v_1 error)
   error])
\end{schemedisplay}
\end{singlespace}

The \scheme{lambdav-subst} metafunction presents the conceptual definition of substitution. We omit the capture-avoidance facilities for clarity.

\subsection{\cm}

\setspecialsymbol{lambdacm}{$\lambda$cm}
\setspecialsymbol{lambdacm-rr}{$\lambda$cm-rr}
\setspecialsymbol{lambdacm-subst}{$\lambda$cm-subst}

Since \cm\ is a superset of \lv, we need only extend the definition of the \lv\ interpreter to accommodate the additions \cm\ brings.

\begin{singlespace}
\begin{schemedisplay}
(define-extended-language lambdacm lambdav
  (e .... (wcm e e) (ccm))
  (E (wcm v F) F)
  (F (E e) (v E) (wcm E e) hole))
\end{schemedisplay}
\end{singlespace}

Redex allows us to easily define a proper extension of a language, inheriting anything left unspecified. As similar as the \lv\ interpeter definition is to the \lv\ definition in figure \ref{lv-language-forms}, this \cm\ interpreter definition is to the \cm\ definition in figure \ref{cm-language-forms}.

\begin{singlespace}
\begin{schemedisplay}
(define lambdacm-rr
  (extend-reduction-relation lambdav-rr lambdacm
   (--> (in-hole E ((lambda (x) e) v))
        (in-hole E (lambdacm-subst x v e))
        "betav")
   (--> (in-hole E (wcm v_1 (wcm v_2 e)))
        (in-hole E (wcm v_2 e))
        "wcm-collapse")
   (--> (in-hole E (wcm v_1 v_2))
        (in-hole E v_2)
        "wcm")
   (--> (in-hole E (ccm))
        (in-hole E (chi E (lambda (x) (lambda (y) y))))
        "chi")
   (--> (in-hole E (wcm error e))
        (in-hole E error)
        "error in wcm mark expression")
   (--> (in-hole E (wcm v error))
        (in-hole E error)
        "error in wcm body expression")))
\end{schemedisplay}
\end{singlespace}

The first three rules in the reduction relation correspond with the three additional semantic rules found in \ref{cm-language-semantics}. The remaining handle cases introduced by the the new language forms' interaction with \scheme'error'.

\begin{singlespace}
\begin{schemedisplay}
(define-metafunction/extension lambdav-subst lambdacm
  lambdacm-subst : x v e -> e
  ;; 1. substitute in wcm form
  [(lambdacm-subst x_1 v_1 (wcm e_1 e_2))
   (wcm (lambdacm-subst x_1 v_1 e_1) (lambdacm-subst x_1 v_1 e_2))]
  ;; 2. substitute in ccm form
  [(lambdacm-subst x_1 v_1 (ccm))
   (ccm)])
\end{schemedisplay}
\end{singlespace}

The \scheme{lambdacm-subst} metafunction is extended to accommodate the additional forms in \cm.

\begin{singlespace}
\begin{schemedisplay}
(define-metafunction lambdacm
  chi : E v -> v
  [(chi hole v_ms)      v_ms]
  [(chi (E e) v_ms)     (chi E v_ms)]
  [(chi (v E) v_ms)     (chi E v_ms)]
  [(chi (wcm E e) v_ms) (chi E v_ms)]
  [(chi (wcm v E) v_ms) (chi E (lambda (p) ((p v) v_ms)))])
\end{schemedisplay}
\end{singlespace}

Finally, we define the $\chi$ metafunction. Its definition does not map directly to the formal definition, but matches the intuitive definition that underlies it.

\section{Transformation testing}
\section{Transformation definition}

\chapter{Proof}

% TODO
% make overline show up in mechanized proof and definitions, where necessary
% label mechanized proof better
% justify each semantic rule with a lemma
% label transition steps
% make beta appear in Redex stuff
% make sure the paper with Jay's suggestions is satisfied


Before setting out on a formal proof, it may be useful to discuss certain invariants that
suggest the transform is correct. In general, there is a direct correspondence between
evaluation states--a context coupled with a possible redex--in \cm\ programs and their
transformations under $\mathcal{C}$. There is also necessarily a correspondence between
the behavior of the original program and its transform. For instance, once an expression
has been decomposed from its context, it is only recomposed with a value or more context.
This is exhibited in the transformed program by the application of the value to the
context, an artifact of the CPS transform which is semantically equivalent to ``filling
the hole''.

We will now set out to demonstrate that $\mathcal{C}$ preserves program meaning.

First, we define some useful shorthand.

\setspecialsymbol{TRUE}{$\mathbf{true}$}
\setspecialsymbol{FALSE}{$\mathbf{false}$}
\setspecialsymbol{PAIR}{$\mathbf{pair}$}
\setspecialsymbol{FST}{$\mathbf{fst}$}
\setspecialsymbol{SND}{$\mathbf{snd}$}
\setspecialsymbol{NIL}{$\mathbf{nil}$}



\setconstant{error}

\begin{defn}
$\true=\abs{x}{\abs{y}{x}}$
\end{defn}

\begin{defn}
$\false=\abs{x}{\abs{y}{y}}$
\end{defn}

\begin{defn}
$\mathbf{pair}=\abs{a}{\abs{b}{\abs{z}{\app{\app{z}{a}}{b}}}}$
\end{defn}

\begin{defn}
$\mathbf{fst}=\abs{p}{\app{p}{\true}}$
\end{defn}

\begin{defn}
$\mathbf{snd}=\abs{p}{\app{p}{\false}}$
\end{defn}

\begin{defn}
$\nil=\false$
\end{defn}

\begin{defn}
If $e\lvrrs v$, $\eval{e}=v$.

The intent of this definition is to preserve visual indicators of the meaning of an
expression. For instance, it is used primarily to allow us to express the pair of $a$ and
$b$ as $\eval{\pair{a}{b}}$ instead of the less recognizable
$\abs{z}{\app{\app{z}{a}}{b}}$. However, it is dangerous since, in the case that $e$
diverges, we refer to a value that doesn't exist. We employ this definition only if it is
obvious that $e$ converges.
\end{defn}

\begin{defn}
$\C{E[e]}=\app{\app{\app{\C{e}}{\C{E}}}{\xi(E)}}{\C{\chi(E)}}$

When applied to both a context and term, $\mathcal{C}$ is treated as a two argument
function. While this in conventionally denoted $\Ct{E}{e}$ or similarly, we adopt the
unorthodox notation for consistency.
\end{defn}

\begin{defn}
$\C{E[v]}=\app{\C{E}}{\Cp{v}}$
\end{defn}

\renewenvironment{schemedefn}[1]{\begin{defn}$#1$\begin{singlespace}}{\end{singlespace}\end{defn}}
\renewenvironment{namedschemedefn}[2]{\begin{defn}\label{#1}$#2$\begin{singlespace}}{\end{singlespace}\end{defn}}

\begin{schemedefn}{\C{\app{e_0}{e_1}}}
\begin{schemedisplay}
(lambda (k)
   (lambda (f)
     (lambda (m)
       (((Ce_0
          (lambda (a)
            (((Ce_1
               (lambda (b)
                 ((((a b) k) f) m)))
              FALSE)
             m)))
         FALSE)
        m))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\C{\wcm{e_0}{e_1}}}
\begin{schemedisplay}
(lambda (k)
  (lambda (f)
    (lambda (m)
      (((Ce_0
         (lambda (n) ((lambda (k) 
                        (k (((m (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
                      (lambda (t) 
                        ((lambda (k) (k ((f C[(SND t)]) t)))
                         (lambda (r) 
                           (((Ce_1 k) TRUE) C[(PAIR v r)])))))))
        FALSE)
       m))))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\C{\ccm}}
\begin{schemedisplay}
(lambda (k)
  (lambda (f)
    (lambda (m)
      (((m k) (lambda (z) z)) (lambda (z) z)))))
\end{schemedisplay}
\end{schemedefn}

\begin{defn}
$\C{v_0}=\C{\abs{x}{e'_0}}=\abs{k}{\abs{f}{\abs{m}{\app{k}{\abs{x}{\C{e'_0}}}}}}$
\end{defn}

\begin{defn}
$\C{x}=\abs{k}{\abs{f}{\abs{m}{\app{k}{x}}}}$
\end{defn}

\begin{defn}
\scheme|C[error]| = \scheme|error|
\end{defn}

\begin{schemedefn}{\C{\hole}}
\begin{schemedisplay}
(lambda (v) C[v])
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\C{E[\app{\hole}{e_1}]}}
\begin{schemedisplay}
(lambda (a)
  (((Ce_1
     (lambda (b)
       ((((a b) CE) xiE) CchiE)))
    FALSE)
   CchiE))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\C{E[\app{v_0}{\hole}]}}
\begin{schemedisplay}
(lambda (b) ((((Cpv_0 b) CE) xiE) CchiE))
\end{schemedisplay}
\end{schemedefn}

\begin{schemedefn}{\C{E[\wcm{\hole}{e_1}]}}
\begin{schemedisplay}
(lambda (n) ((lambda (k) 
               (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
             (lambda (t) 
               ((lambda (k) (k ((f C[(SND t)]) t)))
                  (lambda (r) 
                    (((Ce_1 CE) TRUE) C[(PAIR v r)]))))))
\end{schemedisplay}
\end{schemedefn}

\begin{namedschemedefn}{c-wcm-v-hole}{\C{E[\wcm{v_0}{\hole}]}}
\begin{schemedisplay}
CE
\end{schemedisplay}
\end{namedschemedefn}

This definition is used solely as an abbreviation within the definition of
$\C{\wcm{e_0}{e_1}}$. Note that it is identical to $\C{\app{e_1}{e_1}}$ except that
$\mathcal{C}$ does not recur in the body of $\mathcal{A}$. Because of this, $\mathcal{A}$
has the property that $\mathcal{A}[\app{\C{e_0}}{\C{e_1}}]=\C{\app{e_0}{e_1}}$. This fact
is used to reinterpret particular terms at certain places in the reduction of
$\C{\wcm{e_0}{e_1}}$. In particular, it is necessary to create pairs in $\mathcal{C}$ ``by
hand'' when manipulating $\C{\chi(E)}$, which is defined in terms of applications in
$\mathcal{C}$.

\begin{defn}
$\Cp{v_0}=\Cp{\abs{x}{e_0}}=\abs{x}{\C{e_0}}$
\end{defn}

\begin{defn}
\[
\xi(E)=\begin{cases}
\mathbf{true} &\text{if $E=E'[\wcm{v'}{\hole}]$ for some $E'$ and $v'$}\\
\mathbf{false} &\text{otherwise}
\end{cases}
\]
\end{defn}

\begin{defn}
\begin{align*}
\chi(\hole)               &= \nil\\
\chi(E[\app{\hole}{e_1}]) &= \chi(E)\\
\chi(E[\app{v_0}{\hole}]) &= \chi(E)\\
\chi(E[\wcm{\hole}{e_1}]) &= \chi(E)\\
\chi(E[\wcm{v_0}{\hole}]) &= \eval{\pair{v_0}{\chi(E)}}\\
\end{align*}
\end{defn}

\begin{defn}
\[
\mathrm{eval}_{cm}(p)=\begin{cases}
v     &\text{if $p\cmrrs v$}\\
\perp &\text{if $p\cmrrs\cdots$}
\end{cases}
\]
\end{defn}

\begin{defn}
\[
\mathrm{eval}_{v}(p)=\begin{cases}
v     &\text{if $p\lvrrs v$}\\
\perp &\text{if $p\lvrrs\cdots$}
\end{cases}
\]
\end{defn}

\begin{lemma}
\label{cm-app}
For all values $\abs{x}{e_0}$ and $\abs{y}{e_1}$, $\app{\Cp{\abs{x}{e_0}}}{\Cp{\abs{y}{e_1}}}\lvrr\C{e_0[x\leftarrow \abs{y}{e_1}]}$.
\end{lemma}

\begin{proof}
\begin{align*}
\app{\Cp{\abs{x}{e_0}}}{\Cp{\abs{y}{e_1}}} = &\app{\abs{x}{\C{e_0}}}{\abs{y}{\C{e_1}}}&\text{by definition of $\mathcal{C}'$}\\
                                       \lvrr &\C{e_0}[x\leftarrow \abs{y}{\C{e_1}}]&\text{by semantics of \lv}\\
                                           = &\C{e_0[x\leftarrow \abs{y}{e_1}}]&\text{Think about it.}
\end{align*}
(It's obvious.)
\end{proof}

\begin{lemma}
\label{hole-context-to-value}
For all values $\abs{x}{e}$, $\app{\C{\hole}}{\Cp{\abs{x}{e}}}=\C{\abs{x}{e}}$.
\end{lemma}

\begin{proof}
\begin{align*}
\app{\C{\hole}}{\Cp{\abs{x}{e}}} = &\app{\abs{v}{\C{v}}}{\Cp{\abs{x}{e}}}\\
                                 = &\app{\abs{v}{\C{v}}}{\abs{x}{\C{e}}}\\
                             \lvrr &\C{v}[v\leftarrow \abs{x}{\C{e}}]\\
                                 = &\C{v[v\leftarrow \abs{x}{e}]}\\
                                 = &\C{\abs{x}{e}}
\end{align*}
\end{proof}

\begin{lemma}
\label{wcm-collapse}
If $E=E'[\wcm{v'}{\hole}]$, then $\chi(E'[\wcm{v_0}{\hole}])=\eval{\pair{v_0}{\app{\mathbf{snd}}{\chi(E)}}}$.
\end{lemma}

\begin{proof}
\begin{align*}
\chi(E'[\wcm{v_0}{\hole}]) &= \eval{\pair{v_0}{\chi(E')}}\\
                           &= \eval{\pair{v_0}{\app{\mathbf{snd}}{\chi(E'[\wcm{v'}{\hole}])}}}\\
                           &= \eval{\pair{v_0}{\app{\mathbf{snd}}{\chi(E)}}}\\
\end{align*}
\end{proof}

\newtheorem*{eqtheorem}{Equivalence Theorem}
\begin{eqtheorem}
For all contexts $E\in\lambda_{cm}$ and expressions $e\in\lambda_{cm}$, $E[e]\cmrrs\cdots\implies\C{E[e]}\lvrrs\cdots$ and $E[e]\cmrrs v\implies\C{E[e]}\lvrrs \C{v}$.
\end{eqtheorem}

We will reason by structural induction on both contexts $E$ and terms $e$. Instead of
nesting the induction, which requires the consideration of $|E|\cdot|e|$ cases, we will
take first $E$ and then $e$ in isolation, in each assuming the correctness of the other,
which requires the consideration of only $|E|+|e|$ cases.

First, we will prove the correctness for terms $e$. Assume that for all contexts $E$,
$E[v']\cmrrs v\implies\C{E[v']}\lvrrs v$.

In each case, let $E$ be an arbitrary context.

\begin{proof}[Case $e=\app{e_0}{e_1}$]
By structural induction, assume that 
\[
E[\app{\hole}{e_1}][e_0]\cmrrs\cdots\implies\C{E[\app{\hole}{e_1}][e_0]}\lvrrs\cdots
\]
and
\[
E[\app{\hole}{e_1}][e_0]\cmrrs E[\app{\hole}{e_1}][v_0]\implies\C{E[\app{\hole}{e_1}][e_0]}\lvrrs\C{E[\app{\hole}{e_1}][v_0]}
\]
and similarly
\[
E[\app{v_0}{\hole}][e_1]\cmrrs\cdots\implies\C{E[\app{v_0}{\hole}][e_1]}\lvrrs\cdots
\]
and
\[
E[\app{v_0}{\hole}][e_1]\cmrrs E[\app{v_0}{\hole}][v_1]\implies\C{E[\app{v_0}{\hole}][e_1]}\lvrrs\C{E[\app{v_0}{\hole}][v_1]}
\]
In each case, divergence is lifted to the entire program. Consider the case where $E[\app{\hole}{e_1}][e_0]\cmrrs E[\app{\hole}{e_1}][v_0]$ and $E[\app{v_0}{\hole}][e_1]\cmrrs E[\app{v_0}{\hole}][v_1]$.

$\C{E[\app{e_0}{e_1}]}\lvrrs\C{E[\app{\hole}{e_1}][e_0]}$, by app1-app7.

$\C{E[\app{\hole}{e_1}][e_0]}\lvrrs\C{E[\app{\hole}{e_1}][v_0]}$, by the induction hypothesis.

$\C{E[\app{\hole}{e_1}][v_0]}\lvrrs\C{E[\app{v_0}{\hole}][e_1]}$, by app8-app9.

$\C{E[\app{v_0}{\hole}][e_1]}\lvrrs\C{E[\app{v_0}{\hole}][v_1]}$, by the induction hypothesis.

$\C{E[\app{v_0}{\hole}][v_1]}\lvrr\C{E[\app{v_0}{v_1}]}$, by app11.

By Lemma \ref{cm-app},
\[
E[\app{v_0}{v_1}]\cmrr E[e']\implies\C{E[\app{v_0}{v_1}]}\lvrrs\C{E[e']}
\]
and $\C{E[e']}\lvrrs\C{E[v']}$ follows by induction.
\end{proof}

\begin{proof}[Case $e=\wcm{e_0}{e_1}$]
By structural induction, assume that 
\[
E[\wcm{\hole}{e_1}][e_0]\cmrrs\cdots\implies\C{E[\wcm{\hole}{e_1}][e_0]}\lvrrs\cdots
\]
and
\[
E[\wcm{\hole}{e_1}][e_0]\cmrrs E[\wcm{\hole}{e_1}][v_0]\implies\C{E[\wcm{\hole}{e_1}][e_0]}\lvrrs\C{E[\wcm{\hole}{e_1}][v_0]}
\]
and similarly
\[
E[\wcm{v_0}{\hole}][e_1]\cmrrs\cdots\implies\C{E[\wcm{v_0}{\hole}][e_1]}\lvrrs\cdots
\]
and
\[
E[\wcm{v_0}{\hole}][e_1]\cmrrs E[\wcm{v_0}{\hole}][v_1]\implies\C{E[\wcm{v_0}{\hole}][e_1]}\lvrrs\C{E[\wcm{v_0}{\hole}][v_1]}
\]
Similar to the case of application, divergence is lifted to the entire program. Consider the case where $E[\wcm{\hole}{e_1}][e_0]\cmrrs E[\wcm{\hole}{e_1}][v_0]$ and $E[\wcm{v_0}{\hole}][e_1]\cmrrs E[\wcm{v_0}{\hole}][v_1]$.


$\C{E[\wcm{e_0}{e_1}]}\lvrrs\C{E[\wcm{\hole}{e_1}][e_0]}$, by wcm1-wcm7.

$\C{E[\wcm{\hole}{e_1}][e_0]}\lvrrs\C{E[\wcm{\hole}{e_1}][v_0]}$, by the induction hypothesis.

\begin{case}{$E=E'[\wcm{v'}{\hole}]$ for some $E'$ and $v'$}

$\C{E'[\wcm{v'}{\wcm{\hole}{e_1}}][v_0]}\lvrrs\C{E'[\wcm{v_0}{\hole}][e_1]}$, by wcm9-wcm18-tail.
\end{case}

\begin{case}{$E\ne E'[\wcm{v'}{\hole}]$ for any $E'$ and $v'$}

$\C{E[\wcm{v_0}{e_1}]}\lvrrs\C{E[\wcm{v_0}{\hole}][e_1]}$, by wcm9-wcm18-no-tail.
\end{case}

Now let 
\[
E''=\begin{cases}
E' &\text{if $E=E'[\wcm{v'}{\hole}]$ for some $E'$ and $v'$}\\
E  &\text{otherwise}
\end{cases}
\]

$\C{E''[\wcm{v_0}{\hole}][e_1]}\lvrrs\C{E''[\wcm{v_0}{\hole}][v_1]}$, by the inductive hypothesis.

$\C{E''[\wcm{v_0}{\hole}][v_1]}=\C{E''[v_1]}$, by wcm19.

\end{proof}

\begin{proof}[Case $e=\ccm$]
$\C{E[\ccm]}\lvrrs\C{E[\chi(E)]}$, by ccm1-ccm3.
\end{proof}

\begin{proof}[Case $e=v$]
$\C{E[v]}\lvrrs\C{E[v]}$, by v1-v2.
\end{proof}

\begin{proof}[Case $e=x$]
$\C{E[x]}\lvrrs$\scheme'C[error]', by x1-x4.
\end{proof}

\begin{proof}[Case $e=$\scheme'error']
% prove E[error] -> error => ((C[error] C[E]) ((pair xi(E)) C[chi(E)])) -> C[error]
\end{proof}

Now, we will prove the correctness for contexts $E$. Assume that for all terms $e$,
$E[e]\cmrrs E[v]\implies\C{E[e]}\lvrrs \C{E[v]}$.

In each case, let $e$ be an arbitrary term which evaluates to $v$.

\begin{proof}{Case $E=\hole$}

$\C{\hole[e]}\lvrrs\C{\hole[v]}$, by assumption.

$\C{\hole[v]}\lvrr\C{v}$, by [a lemma].
\end{proof}

\begin{proof}{Case $E=E'[\app{\hole}{e_1}]$}

$\C{E'[\app{\hole}{e_1}][e_0]}\lvrrs\C{E'[\app{\hole}{e_1}][v_0]}$, by assumption.

$\C{E'[\app{\hole}{e_1}][v_0]}\lvrr\C{E'[\app{v_0}{\hole}][e_1]}$, by app8.

We defer to the inductive hypothesis.
\end{proof}

\begin{proof}{Case $E=E'[\app{v_0}{\hole}]$}

$\C{E'[\app{v_0}{\hole}][e_1]}\lvrrs\C{E'[\app{v_0}{\hole}][v_1]}$, by assumption.

$\C{E'[\app{v_0}{\hole}][v_1]}\lvrr\C{E'[\app{v_0}{v_1}]}$, by app9.

$\C{E'[\app{v_0}{v_1}]}\lvrr\C{E'[e]}$ for some $e$, by assumption.

We defer to the inductive hypothesis.
\end{proof}

\begin{proof}{Case $E=E'[\wcm{\hole}{e_1}]$}

$\C{E'[\wcm{\hole}{e_1}][e_0]}\lvrrs\C{E'[\wcm{\hole}{e_1}][v_0]}$, by assumption.

\begin{case}{$E'=E''[\wcm{v'}{\hole}]$ for some $E''$ and $v'$}

$\C{E'[\wcm{\hole}{e_1}][v_0]}\lvrrs\C{E''[\wcm{v_0}{\hole}][e_1]}$, by wcm9-wcm18-tail.
\end{case}

\begin{case}{$E'\ne E''[\wcm{v'}{\hole}]$ for any $E''$ and $v'$}

$\C{E'[\wcm{\hole}{e_1}][v_0]}\lvrrs\C{E'[\wcm{v_0}{\hole}][e_1]}$, by wcm9-wcm18-not-tail.
\end{case}

We defer to the inductive hypothesis.
\end{proof}

\begin{proof}{Case $E=E'[\wcm{v'}{\hole}]$}

$\C{E'[\wcm{v'}{\hole}][e]}\lvrrs\C{E'[\wcm{v'}{\hole}][v]}$, by assumption.

$\C{E'[\wcm{v'}{\hole}][v]}\lvrr \C{E'[v]}$, by wcm19. 
\end{proof}

\newtheorem*{maintheorem}{Correctness of $\mathcal{C}$}
\begin{maintheorem}
For all programs $p\in\lambda_{cm}$, $\C{\mathrm{eval}_{cm}(p)}=\mathrm{eval}_{v}(\C{p})$.
\end{maintheorem}

\begin{proof}

\begin{align*}
p\cmrrs v &\implies\mathrm{eval}_{cm}(p)=v &\text{(by definition of $\mathrm{eval}_{cm}$)}\\
          &\implies\C{\mathrm{eval}_{cm}(p)}=\C{v} &\text{(by well-definedness of $\mathcal{C}$)}
\end{align*}

% define C[E[e]]
% define C[E]
% define C[e]

% E[(e0 e1)] *
% E[(* e1)][e0] *
% E[(* e1)][v0] *
% E[(v0 e1)] ~
% E[(v0 *)][e1] *
% E[(v0 *)][v1] *
% E[(v0 v1)] ~*
% E[e2] * by induction

% E[(wcm e0 e1)] *
% E[(wcm * e1)][e0] *
% E[(wcm * e1)][v0] *
% E[(wcm v0 e1)] ~
% E[(wcm v0 *)][e1] ~?
% E[(wcm v0 *)][v1] ~?
% E[(wcm v0 v1)] ~
% E[v1] *

% E'[(wcm v' *][(wcm e0 e1)] *
% E'[(wcm v' (wcm * e1))][e0] *
% E'[(wcm v' (wcm * e1))][v0] ~
% E'[(wcm v' (wcm v0 e1))] ~
% E'[(wcm v0 e1)] ~
% E'[(wcm v0 *)][e1] ~?
% E'[(wcm v0 *)][v1] ~
% E'[(wcm v0 v1)] ~
% E'[v1] *

% E[(ccm)] *
% E[chi(E)] *

% define C[E[v]] (C[E] C'[v])

\begin{align*}
p\cmrrs v &\implies\hole[p]\cmrrs v &\text{(since $p\cmrr\hole[p]$)}\\
          &\implies\C{\hole[p]}\lvrrs\C{v} &\text{(by the Great Lemma)}\\
          &\implies\app{\app{\C{p}}{\C{\hole}}}{\eval{\pair{\xi(\hole)}{\C{\chi(\hole)}}}}\lvrrs\C{v}&\text{(by definition of $\mathcal{C}$)}\\
          &\implies\mathrm{eval}_{v}(\C{p})=\C{v} &\text{(by definition of $\mathrm{eval}_v$)}
\end{align*}

Therefore, $\C{\mathrm{eval}_{cm}(p)}=\mathrm{eval}_{v}(\C{p})$.
\end{proof}

\chapter{Conclusion}

Continuation marks support a bevy of instrumentation tools and advanced language features in a generalized, portable way. Despite their demonstrated utility, they have not yet found their way into most languages. A verified characterization of continuation marks in a pure computational language provides implementors of higher-order languages a correct compiler for continuation marks.

\bibliographystyle{plainnat}
\bibliography{dissertation}

\appendix
\chapter{Mechanical Proof}

\newcommand{\trans}[2]{#1#2}

\begin{singlespace}

application

\trans{app}{0}
\begin{schemedisplay}
E[(e_0 e_1)]
\end{schemedisplay}
\begin{schemedisplay}
(((C[(e_0 e_1)] C[E]) xiE) CchiE)
\end{schemedisplay}
\trans{=}{0}
\begin{schemedisplay}
((((lambda (k)
     (lambda (f)
       (lambda (m)
         (((Ce_0
            (lambda (a)
              (((Ce_1
                 (lambda (b)
                   ((((a b) k) f) m)))
                FALSE)
               m)))
           FALSE)
          m)))) CE) xiE) CchiE)
\end{schemedisplay}

app1
\begin{schemedisplay}
(((lambda (f)
    (lambda (m)
      (((Ce_0
         (lambda (a)
           (((Ce_1
              (lambda (b)
                ((((a b) CE) f) m)))
             FALSE)
            m)))
        FALSE)
       m))) xiE) CchiE)
\end{schemedisplay}

app2
\begin{schemedisplay}
((lambda (m)
   (((Ce_0
      (lambda (a)
        (((Ce_1
           (lambda (b)
             ((((a b) CE) xiE) m)))
          FALSE)
         m)))
     FALSE)
    m)) CchiE)
\end{schemedisplay}

app3
\begin{schemedisplay}
E[(hole e_1)][e_0]
\end{schemedisplay}
\begin{schemedisplay}
(((Ce_0
   (lambda (a)
     (((Ce_1
        (lambda (b)
          ((((a b) CE) xiE) CchiE)))
       FALSE)
      CchiE)))
  FALSE)
 CchiE)
\end{schemedisplay}

e0 error

app4-error
\begin{schemedisplay}
((lambda (a)
   (((Ce_1
      (lambda (b)
        ((((a b) CE) xiE) CchiE)))
     FALSE)
    CchiE)) error)
\end{schemedisplay}

app5-error
\begin{schemedisplay}
error
\end{schemedisplay}

e0 nontermination

app4-bottom
\begin{schemedisplay}
((lambda (a)
   (((Ce_1
      (lambda (b)
        ((((a b) CE) xiE) CchiE)))
     FALSE)
    CchiE)) bottom)
\end{schemedisplay}

app5-bottom
\begin{schemedisplay}
bottom
\end{schemedisplay}

app4
\begin{schemedisplay}
E[(hole e_1)][v_0]
\end{schemedisplay}
\begin{schemedisplay}
((lambda (a)
   (((Ce_1
      (lambda (b)
        ((((a b) CE) xiE) CchiE)))
     FALSE)
    CchiE)) Cpv_0)
\end{schemedisplay}

app5
\begin{schemedisplay}
E[(v_0 hole)][e_1]
\end{schemedisplay}
\begin{schemedisplay}
(((Ce_1
   (lambda (b)
     ((((Cpv_0 b) CE) xiE) CchiE)))
  FALSE)
 CchiE)
\end{schemedisplay}

find home for me
\begin{schemedisplay}
E[(v_0 e_1)]
\end{schemedisplay}

e1 error

app6-error
\begin{schemedisplay}
((lambda (b) ((((Cpv_0 b) CE) xiE) CchiE)) error)
\end{schemedisplay}

app6-error
\begin{schemedisplay}
error
\end{schemedisplay}

e1 nontermination

app6-bottom
\begin{schemedisplay}
((lambda (b) ((((Cpv_0 b) CE) xiE) CchiE)) bottom)
\end{schemedisplay}

app6-error
\begin{schemedisplay}
bottom
\end{schemedisplay}

app6
\begin{schemedisplay}
E[(v_0 hole)][v_1]
\end{schemedisplay}
\begin{schemedisplay}
((lambda (b) ((((Cpv_0 b) CE) xiE) CchiE)) Cpv_1)
\end{schemedisplay}

app7
\begin{schemedisplay}
E[(v_0 v_1)]
\end{schemedisplay}
\begin{schemedisplay}
((((Cpv_0 Cpv_1) CE) xiE) CchiE)
\end{schemedisplay}

=
\begin{schemedisplay}
E[((lambda (x) e_0p) v_1)]
\end{schemedisplay}
\begin{schemedisplay}
((((lambda (x) Ce_0p) Cpv_1) CE) ((PAIR xiE) CchiE))
\end{schemedisplay}

app8
\begin{schemedisplay}
(((Ce_0p_x_Cpv_1 CE) xiE) CchiE)
\end{schemedisplay}

=
\begin{schemedisplay}
E[e_0p_x_v_1]
\end{schemedisplay}
\begin{schemedisplay}
(((C[e_0p_x_v_1] CE) xiE) CchiE)
\end{schemedisplay}


wcm0
\begin{schemedisplay}
E[(wcm e_0 e_1)]
\end{schemedisplay}
\begin{schemedisplay}
(((C[(wcm e_0 e_1)] CE) xiE) CchiE)
\end{schemedisplay}

=
\begin{schemedisplay}
((((lambda (k)
     (lambda (f)
       (lambda (m)
         (((Ce_0
            (lambda (n) ((lambda (k) 
                           (k (((m (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
                         (lambda (t) 
                           ((lambda (k) (k ((f C[(SND t)]) t)))
                              (lambda (r) 
                                (((Ce_1 k) TRUE) C[(PAIR v r)])))))))
           FALSE)
          m)))) CE) xiE) CchiE)
\end{schemedisplay}

wcm1
\begin{schemedisplay}
(((lambda (f)
    (lambda (m)
      (((Ce_0
         (lambda (n) ((lambda (k) 
                        (k (((m (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
                      (lambda (t) 
                        ((lambda (k) (k ((f C[(SND t)]) t)))
                           (lambda (r) 
                             (((Ce_1 CE) TRUE) C[(PAIR v r)])))))))
        FALSE)
       m))) xiE) CchiE)
\end{schemedisplay}

wcm2
\begin{schemedisplay}
((lambda (m)
   (((Ce_0
      (lambda (n) ((lambda (k) 
                     (k (((m (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
                   (lambda (t) 
                     ((lambda (k) (k ((f C[(SND t)]) t)))
                        (lambda (r) 
                          (((Ce_1 CE) TRUE) C[(PAIR v r)])))))))
     FALSE)
    m)) CchiE)
\end{schemedisplay}

wcm3
\begin{schemedisplay}
E[(wcm hole e_1)][e_0]
\end{schemedisplay}
\begin{schemedisplay}
(((Ce_0
   (lambda (n) ((lambda (k) 
                  (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
                (lambda (t) 
                  ((lambda (k) (k ((f C[(SND t)]) t)))
                     (lambda (r) 
                       (((Ce_1 CE) TRUE) C[(PAIR v r)])))))))
  FALSE)
 CchiE)
\end{schemedisplay}

error

wcm4-error
\begin{schemedisplay}
((lambda (n) ((lambda (k) 
                (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
              (lambda (t) 
                ((lambda (k) (k ((f C[(SND t)]) t)))
                   (lambda (r) 
                     (((Ce_1 CE) TRUE) C[(PAIR v r)])))))) error)
\end{schemedisplay}

wcm5-error
\begin{schemedisplay}
error
\end{schemedisplay}


nontermination

wcm4-nontermination
\begin{schemedisplay}
((lambda (n) ((lambda (k) 
                (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
              (lambda (t) 
                ((lambda (k) (k ((f C[(SND t)]) t)))
                   (lambda (r) 
                     (((Ce_1 CE) TRUE) C[(PAIR v r)])))))) bottom)
\end{schemedisplay}

wcm5-nontermintation
\begin{schemedisplay}
bottom
\end{schemedisplay}

wcm4
\begin{schemedisplay}
((lambda (n) ((lambda (k) 
                (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
              (lambda (t) 
                ((lambda (k) (k ((f C[(SND t)]) t)))
                   (lambda (r) 
                     (((Ce_1 CE) TRUE) C[(PAIR v r)])))))) Cpv_0)
\end{schemedisplay}

wcm5
\begin{schemedisplay}
((lambda (k) 
   (k (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z))))
 (lambda (t) 
   ((lambda (k) (k ((f C[(SND t)]) t)))
      (lambda (r) 
        (((Ce_1 CE) TRUE) C[(PAIR v_0 r)])))))
\end{schemedisplay}

wcm6
\begin{schemedisplay}
((lambda (t) 
   ((lambda (k) (k ((f C[(SND t)]) t)))
      (lambda (r)
        (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))))
 (((CchiE (lambda (x) x)) (lambda (z) z)) (lambda (z) z)))
\end{schemedisplay}

wcm7
\begin{schemedisplay}
((lambda (t) 
   ((lambda (k) (k ((f C[(SND t)]) t)))
      (lambda (r)
        (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))))
 Cp[chiE])
\end{schemedisplay}

wcm8
\begin{schemedisplay}
((lambda (k) (k ((xiE C[(SND chiE)]) Cp[chiE])))
 (lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)])))
\end{schemedisplay}

wcm9
\begin{schemedisplay}
((lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))
 ((xiE C[(SND chiE)]) Cp[chiE]))
\end{schemedisplay}

wcm9-tail
\begin{schemedisplay}
((lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))
 ((TRUE C[(SND chiE)]) Cp[chiE]))
\end{schemedisplay}

wcm10-tail
\begin{schemedisplay}
((lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))
 C[(SND chiE)])
\end{schemedisplay}

wcm11-tail
\begin{schemedisplay}
(((Ce_1 CE) TRUE) C[(PAIR v_0 (SND chiE))])
\end{schemedisplay}

wcm9-non-tail
\begin{schemedisplay}
((lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))
 ((FALSE (SND chiE) Cp[chiE)]))
\end{schemedisplay}

wcm10-non-tail
\begin{schemedisplay}
((lambda (r) (((Ce_1 CE) TRUE) C[(PAIR v_0 r)]))
 Cp[chiE])
\end{schemedisplay}

wcm11-non-tail
\begin{schemedisplay}
(((Ce_1 CE) TRUE) C[(PAIR v_0 chiE)])
\end{schemedisplay}


find homes for us
\begin{schemedisplay}
nu(E)[(wcm v_0 hole)][e_1]
\end{schemedisplay}

\begin{schemedisplay}
nu(E)[(wcm v_0 hole)][v_1]
\end{schemedisplay}

\begin{schemedisplay}
nu(E)[(wcm v_0 v_1)]
\end{schemedisplay}
\begin{schemedisplay}
nu(E)[v_1]
\end{schemedisplay}

ccm
\begin{schemedisplay}
E[(ccm)]
\end{schemedisplay}

\begin{schemedisplay}
E[chiE]
\end{schemedisplay}

\begin{schemedisplay}
((C[(ccm)] CE) ((PAIR xiE) CchiE))
\end{schemedisplay}

ccm0
\begin{schemedisplay}
((((lambda (k)
     (lambda (f)
       (lambda (m)
         (((m k) FALSE) m)))
   CE) xiE) CchiE)
\end{schemedisplay}

ccm1
\begin{schemedisplay}
(((lambda (f)
    (lambda (m)
      (((m CE) FALSE) m))
  xiE) CchiE)
\end{schemedisplay}

ccm2
\begin{schemedisplay}
((lambda (m)
   (((m CE) FALSE) m))
 CchiE)
\end{schemedisplay}

ccm3
\begin{schemedisplay}
(((CchiE CE) FALSE) CchiE)
\end{schemedisplay}

// appeal to value here

variable
\begin{schemedisplay}
E[x]
\end{schemedisplay}

\begin{schemedisplay}
E[error]
\end{schemedisplay}

\begin{schemedisplay}
(((C[x] CE) xiE) CchiE)
\end{schemedisplay}

x0
\begin{schemedisplay}
((((lambda (k) (lambda (f) (lambda (m) (k x))) CE) xiE) CchiE)
\end{schemedisplay}

x1
\begin{schemedisplay}
(((lambda (f) (lambda (m) (CE x)) xiE) CchiE)
\end{schemedisplay}

x2
\begin{schemedisplay}
((lambda (m) (CE x)) CchiE)
\end{schemedisplay}

x3
\begin{schemedisplay}
(CE x)
\end{schemedisplay}

x4
\begin{schemedisplay}
(CE error)
\end{schemedisplay}

x5
\begin{schemedisplay}
error
\end{schemedisplay}

value
\begin{schemedisplay}
E[v]
\end{schemedisplay}

\begin{schemedisplay}
(((Cv_0 CE) xiE) CchiE)
\end{schemedisplay}

v0
\begin{schemedisplay}
((((lambda (k) (lambda (f) (lambda (m) (k Cpv_0))) CE) xiE) CchiE)
\end{schemedisplay}

v1
\begin{schemedisplay}
(((lambda (f) (lambda (m) (CE Cpv_0))) xiE) CchiE)
\end{schemedisplay}

v2
\begin{schemedisplay}
((lambda (m) (CE Cpv_0)) CchiE)
\end{schemedisplay}

v3
\begin{schemedisplay}
(CE Cpv_0)
\end{schemedisplay}
\end{singlespace}

\end{document}
